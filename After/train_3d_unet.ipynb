{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "\n",
    "from utils.dcm_utils import *\n",
    "from utils.nii_utils import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Volumes/SSD970/\"\n",
    "TRAIN_SEG_DIR = os.path.join(DATA_DIR, \"segmentations\")\n",
    "TRAIN_IMAGE_DIR = os.path.join(DATA_DIR, \"train_images\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_patient_dcm() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/3l/2d1zfhx90z18_kvtkwwz9xtw0000gn/T/ipykernel_28477/2886332067.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSegmentationDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTRAIN_IMAGE_DIR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTRAIN_SEG_DIR\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m \u001B[0mimage\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/3l/2d1zfhx90z18_kvtkwwz9xtw0000gn/T/ipykernel_28477/2886332067.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 20\u001B[0;31m         \u001B[0mimgs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimage_positions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimage_orientations\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpixel_spacings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mslice_thicknesses\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_flip\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mread_patient_dcm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mUID\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mimage_dir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     21\u001B[0m         \u001B[0mheight\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimage_positions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mimage_positions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     22\u001B[0m         \u001B[0mpixel_spacing\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpixel_spacings\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: read_patient_dcm() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, seg_dir, transform=None, target_transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.seg_dir = seg_dir\n",
    "\n",
    "        self.nii_files = glob.glob(seg_dir + \"/*.nii\")\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.nii_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        nii_path = self.nii_files[idx]\n",
    "        UID = nii_path.split(\"/\")[-1].replace(\".nii\", \"\")\n",
    "\n",
    "\n",
    "        imgs, image_positions, image_orientations, pixel_spacings, slice_thicknesses, is_flip = read_patient_dcm(UID, self.image_dir)\n",
    "        height = image_positions[0, 2] - image_positions[1, 2]\n",
    "        pixel_spacing = pixel_spacings[0, 0]\n",
    "        aspect = np.round(height / pixel_spacing)\n",
    "        img3d = np.repeat(imgs, aspect, axis=0)\n",
    "\n",
    "        # get segmentation\n",
    "        seg = read_patient_nii_mask(UID, self.seg_dir)\n",
    "        if is_flip is False:\n",
    "            seg = np.flip(seg, axis=0)\n",
    "        seg3d = np.repeat(seg, aspect, axis=0)\n",
    "\n",
    "        if self.transform:\n",
    "            img3d = self.transform(img3d)\n",
    "        if self.target_transform:\n",
    "            seg3d = self.target_transform(seg3d)\n",
    "        return img3d, seg3d\n",
    "\n",
    "\n",
    "dataset = SegmentationDataset(TRAIN_IMAGE_DIR, TRAIN_SEG_DIR)\n",
    "print(len(dataset))\n",
    "image, label = dataset[0]\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=1,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "Unet(\n  (encoder): ResNetEncoder(\n    (conv1): Conv3d(1, 64, kernel_size=(7, 7, 7), stride=(2, 2, 2), padding=(3, 3, 3), bias=False)\n    (bn1): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n          (1): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n          (1): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(512, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(512, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n          (1): BatchNorm3d(512, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn1): BatchNorm3d(512, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n        (bn2): BatchNorm3d(512, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (decoder): UnetDecoder(\n    (center): Identity()\n    (blocks): ModuleList(\n      (0): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv3d(768, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(256, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(128, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(64, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(32, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(32, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (4): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv3d(32, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(16, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n          (1): BatchNorm3d(16, eps=1e-05, momentum=True, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n    )\n  )\n  (segmentation_head): SegmentationHead(\n    (0): Conv3d(16, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (1): Identity()\n    (2): Activation(\n      (activation): Identity()\n    )\n  )\n)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_3d(module):\n",
    "\n",
    "    new_module = module\n",
    "    if isinstance(module, nn.Conv2d):\n",
    "        new_module = nn.Conv3d(module.in_channels,\n",
    "                               module.out_channels,\n",
    "                               kernel_size=module.kernel_size[0],\n",
    "                               stride=module.stride[0],\n",
    "                               padding=module.padding[0],\n",
    "                               bias=module.bias)\n",
    "    elif isinstance(module, nn.BatchNorm2d):\n",
    "        new_module = nn.BatchNorm3d(module.num_features,\n",
    "                                    module.eps,\n",
    "                                    module.affine,\n",
    "                                    module.track_running_stats)\n",
    "    elif isinstance(module, nn.MaxPool2d):\n",
    "        new_module = nn.MaxPool3d(kernel_size=module.kernel_size,\n",
    "                                  stride=module.stride,\n",
    "                                  padding=module.padding,\n",
    "                                  dilation=module.dilation,\n",
    "                                  ceil_mode=module.ceil_mode)\n",
    "\n",
    "    for name, child_module in new_module.named_children():\n",
    "        setattr(new_module, name, convert_3d(child_module))\n",
    "\n",
    "    return new_module\n",
    "\n",
    "model_3d = convert_3d(model)\n",
    "model_3d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 1, 128, 128, 128])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 128, 128, 128)\n",
    "out = model(x)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Group: 0 TRAIN: [2 3 4 5 6 7 8 9] TEST: [0 1]\n",
      "Group: 1 TRAIN: [0 1 4 5 6 7 8 9] TEST: [2 3]\n",
      "Group: 2 TRAIN: [0 1 2 3 6 7 8 9] TEST: [4 5]\n",
      "Group: 3 TRAIN: [0 1 2 3 4 5 8 9] TEST: [6 7]\n",
      "Group: 4 TRAIN: [0 1 2 3 4 5 6 7] TEST: [8 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "for group, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    print(\"Group:\", group, \"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object _BaseKFold.split at 0x7fdab5ce3c80>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
