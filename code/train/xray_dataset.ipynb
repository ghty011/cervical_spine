{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "wd = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlongyi\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/longyi/Desktop/StudyCode/CervicalSpine/code/train/wandb/run-20220909_134441-2geilwf1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"http://8.219.189.100:8081/longyi/cervical-spine/runs/2geilwf1\" target=\"_blank\">drawn-dawn-9</a></strong> to <a href=\"http://8.219.189.100:8081/longyi/cervical-spine\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_entity='longyi'\n",
    "model_name = \"resnet50\"\n",
    "wandb.init(project=\"cervical-spine\", entity=wandb_entity, config={\n",
    "    \"model\":model_name,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"lr\" : lr,\n",
    "    \"wd\" : wd\n",
    "})\n",
    "wandb.run.name = f'xray_{model_name}_' + datetime.now().strftime(\"%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils.dcm_utils import *\n",
    "from utils.nii_utils import *\n",
    "from utils.train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, CenterCrop\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"/media/longyi/SSD9701/\"\n",
    "TRAIN_XRAY_DIR = os.path.join(DATA_DIR, \"xray_images\")\n",
    "TRAIN_IMAGE_DIR = os.path.join(DATA_DIR, \"train_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, xray_dir, label_df, transform=None, target_transform=None):\n",
    "        self.xray_dir = xray_dir\n",
    "        self.label_df = label_df\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.label_df.iloc[idx]\n",
    "        UID = row.name\n",
    "        label = torch.tensor(row[['patient_overall', 'C1','C2','C3','C4','C5','C6','C7']])\n",
    "\n",
    "        axial = read_image(os.path.join(self.xray_dir, UID, 'axial.jpeg')).float()\n",
    "        sagittal = read_image(os.path.join(self.xray_dir, UID, 'sagittal.jpeg')).float()\n",
    "        coronal = read_image(os.path.join(self.xray_dir, UID, 'coronal.jpeg')).float()\n",
    "\n",
    "        if self.transform:\n",
    "            axial = self.transform(axial)\n",
    "            sagittal = self.transform(sagittal)\n",
    "            coronal = self.transform(coronal)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return (axial, sagittal, coronal), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'train_clean.csv')).set_index('StudyInstanceUID')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.6200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.27262</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.21561</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.12351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.1363</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient_overall  C1  C2  C3  C4  C5  C6  C7\n",
       "StudyInstanceUID                                                      \n",
       "1.2.826.0.1.3680043.6200                 1   1   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.1363                 1   0   0   0   0   1   0   0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1609 eval 403\n"
     ]
    }
   ],
   "source": [
    "total_len = len(df)\n",
    "train_to = int(total_len * 0.8)\n",
    "train_df = df.iloc[:train_to]\n",
    "eval_df = df.iloc[train_to:]\n",
    "\n",
    "print(f\"train {len(train_df)} eval {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageTransform:\n",
    "    \"\"\"Rotate by one of the given angles.\"\"\"\n",
    "\n",
    "    def __init__(self, wh):\n",
    "        self.wh = wh\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h, w = float(x.shape[1]), float(x.shape[2])\n",
    "\n",
    "        if h > w:\n",
    "            x = TF.resize(x, [int(self.wh), int(self.wh * w / h)])\n",
    "        else:\n",
    "            x = TF.resize(x, [int(self.wh * h / w), int(self.wh)])\n",
    "\n",
    "        x = TF.center_crop(x, self.wh)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           ...,\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "           [-1., -1., -1.,  ..., -1., -1., -1.]]]),\n",
       "  tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]),\n",
       "  tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]])),\n",
       " tensor([1, 1, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    Normalize(255 * 0.5, 255 * 0.5),\n",
    "    ImageTransform(224.)\n",
    "])\n",
    "target_transform = None\n",
    "train_dataset = XrayDataset(TRAIN_XRAY_DIR, train_df, transform=transform, target_transform=target_transform)\n",
    "eval_dataset = XrayDataset(TRAIN_XRAY_DIR, eval_df, transform=transform, target_transform=target_transform)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 0.8939855098724365\n"
     ]
    }
   ],
   "source": [
    "(a, s, c), y = train_dataset[0]\n",
    "print(f\"{s.min()} {s.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class XrayModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sagittal_feature = self._make_feature_extractor()\n",
    "        self.coronal_feature = self._make_feature_extractor()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(2048 * 2, 1, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d((7, 1)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "\n",
    "    def _make_feature_extractor(self):\n",
    "        feature = torchvision.models.resnet50(pretrained=True)\n",
    "        conv1_weight = feature.conv1.weight\n",
    "        new_conv1_weight = conv1_weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "        feature.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=2, padding=3, bias=False)\n",
    "        feature.conv1.weight = nn.Parameter(new_conv1_weight, requires_grad=True)\n",
    "        feature.avgpool = nn.AdaptiveAvgPool2d((7, 1))\n",
    "\n",
    "        return nn.Sequential(\n",
    "            *list(feature.children())[:-1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        (_, sagittal, coronal) = x\n",
    "        sagittal_feature = self.sagittal_feature(sagittal)\n",
    "        coronal_feature = self.coronal_feature(coronal)\n",
    "\n",
    "        out = torch.cat((sagittal_feature, coronal_feature), dim=1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XrayModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 1, 224, 224)\n",
    "out = model((None, input, input))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, labels):\n",
    "    # logits N x 7\n",
    "    # labels N x 7\n",
    "    weights = calculate_weights(labels)[:, 1:]\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, labels[:, 1:].to(torch.float), reduction='none')\n",
    "    loss = weights * loss\n",
    "\n",
    "    weights_sum = weights.sum(dim=1)\n",
    "    # overall_loss = loss[:, 0] / weights_sum\n",
    "    # c_loss = loss[:, 1:].sum(dim=1) / weights_sum\n",
    "    return loss.sum(dim=1) / weights_sum    # N x 1\n",
    "    # return overall_loss.mean(), c_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(epoch):\n",
    "    model.eval()\n",
    "    eval_iter = tqdm(eval_loader)\n",
    "\n",
    "    losses = []\n",
    "    for i, (x, y) in enumerate(eval_iter):\n",
    "        x = (v.to(device) for v in x)\n",
    "        y = y.to(device=device)\n",
    "\n",
    "        logits = model(x)\n",
    "        c_loss = loss_fn(logits, y).mean()\n",
    "        loss = c_loss\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # accuracy\n",
    "        pred = logits.sigmoid().ge(0.5).int()\n",
    "        correct = (y[:, 1:] == pred).float().mean(dim=0)\n",
    "        # overall_acc = correct[0]\n",
    "        c_acc = correct.mean()\n",
    "\n",
    "        eval_iter.set_description(f\"e {epoch} loss {loss.item():.4f} c_acc {c_acc.item():.4f}\")\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                # 'eval_overall_loss' : overall_loss.item(),\n",
    "                'eval_c_loss' : c_loss.item(),\n",
    "                # 'eval_loss': loss.item(),\n",
    "                # 'eval_overall_acc' : overall_acc.item(),\n",
    "                'eval_c_acc' : c_acc.item(),\n",
    "                'epoch' : epoch\n",
    "            })\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e 0 loss 0.8254 c_acc 0.1429: 100%|██████████| 26/26 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.818001960332577"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    train_iter = tqdm(train_loader)\n",
    "    losses = []\n",
    "    for i, (x, y) in enumerate(train_iter):\n",
    "        x = (v.to(device) for v in x)\n",
    "        y = y.to(device=device)\n",
    "\n",
    "        logits = model(x)\n",
    "        c_loss = loss_fn(logits, y).mean()\n",
    "        loss = c_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        train_iter.set_description(f\"t {epoch} loss {loss.item():.4f}\")\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'train_c_loss' : c_loss.item(),\n",
    "                'train_loss': loss.item(),\n",
    "                'epoch': epoch\n",
    "            })\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 0 loss 0.2626: 100%|██████████| 101/101 [00:22<00:00,  4.52it/s]\n",
      "e 0 loss 0.1576 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train_loss 0.42431435874193024 eval_loss 0.5007594863955791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 1 loss 0.3351: 100%|██████████| 101/101 [00:22<00:00,  4.51it/s]\n",
      "e 1 loss 0.2270 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 train_loss 0.4207012907113179 eval_loss 0.43375348586302537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 2 loss 0.4546: 100%|██████████| 101/101 [00:22<00:00,  4.52it/s]\n",
      "e 2 loss 0.3153 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 train_loss 0.4205962292628713 eval_loss 0.4462386851127331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 3 loss 0.4249: 100%|██████████| 101/101 [00:22<00:00,  4.51it/s]\n",
      "e 3 loss 0.2673 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 train_loss 0.41800362697922355 eval_loss 0.4265523999929428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 4 loss 0.6251: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 4 loss 0.2647 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 train_loss 0.4189772647206146 eval_loss 0.4285938504796762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 5 loss 0.2578: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 5 loss 0.2178 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 train_loss 0.41648867357485364 eval_loss 0.42614292525328124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 6 loss 0.3527: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 6 loss 0.2312 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 train_loss 0.41456912354667586 eval_loss 0.428437549334306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 7 loss 0.3633: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 7 loss 0.2385 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 train_loss 0.42270132132095867 eval_loss 0.42388704189887416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 8 loss 0.3846: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 8 loss 0.2577 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 train_loss 0.41712737791609056 eval_loss 0.4205113718142876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 9 loss 0.2723: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 9 loss 0.2288 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 train_loss 0.4144848378578035 eval_loss 0.42647304557836974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 10 loss 0.3969: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 10 loss 0.2261 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 train_loss 0.4114390709022484 eval_loss 0.43780362147551316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 11 loss 0.3734: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 11 loss 0.2424 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 train_loss 0.41138519922105393 eval_loss 0.42548339527386886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 12 loss 0.3005: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 12 loss 0.2261 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 train_loss 0.40853525270329843 eval_loss 0.42673974254956615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 13 loss 0.3975: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 13 loss 0.2522 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 train_loss 0.4077910990408151 eval_loss 0.4311172136893639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 14 loss 0.3160: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 14 loss 0.2327 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 train_loss 0.40471826139653083 eval_loss 0.44202773387615496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 15 loss 0.4168: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 15 loss 0.2317 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 train_loss 0.3997894403072867 eval_loss 0.43816587099662196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 16 loss 0.2464: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 16 loss 0.1819 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 train_loss 0.39407939663027775 eval_loss 0.5018913373351097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 17 loss 0.3756: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 17 loss 0.2378 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 train_loss 0.39212028918289904 eval_loss 0.42915226404483503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 18 loss 0.3804: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 18 loss 0.1964 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 train_loss 0.38674286155417414 eval_loss 0.4671921827472173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 19 loss 0.2885: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 19 loss 0.1563 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 train_loss 0.3717497044270582 eval_loss 0.47960586616626155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 20 loss 0.4435: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 20 loss 0.1865 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 train_loss 0.36352676640052606 eval_loss 0.49377760405723864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 21 loss 0.3375: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 21 loss 0.1358 c_acc 1.0000: 100%|██████████| 26/26 [00:01<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 train_loss 0.34343851232292627 eval_loss 0.5060342332491508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 22 loss 0.3836: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 22 loss 0.2030 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 train_loss 0.3207292994945356 eval_loss 0.539755856188444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 23 loss 0.3965: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 23 loss 0.1692 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 train_loss 0.3010857230660939 eval_loss 0.5748364615898865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 24 loss 0.4138: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 24 loss 0.1566 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 train_loss 0.2708729754875202 eval_loss 0.5956427082419395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 25 loss 0.2287: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 25 loss 0.1157 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 train_loss 0.23321047351501956 eval_loss 0.7983201372508819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 26 loss 0.2057: 100%|██████████| 101/101 [00:22<00:00,  4.50it/s]\n",
      "e 26 loss 0.2213 c_acc 0.8095: 100%|██████████| 26/26 [00:01<00:00, 13.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 train_loss 0.20118577055411763 eval_loss 0.8084969979066116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 27 loss 0.2268: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 27 loss 0.1123 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 train_loss 0.17151296544488115 eval_loss 0.8501562748390895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 28 loss 0.1768: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 28 loss 0.1919 c_acc 0.9048: 100%|██████████| 26/26 [00:01<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 train_loss 0.1434491232480153 eval_loss 0.9573345757447757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 29 loss 0.1062: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 29 loss 0.0952 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 train_loss 0.12117136419188268 eval_loss 0.9908986054360867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 30 loss 0.0742: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 30 loss 0.0954 c_acc 0.9524: 100%|██████████| 26/26 [00:02<00:00, 12.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 train_loss 0.11532658906561313 eval_loss 1.112879946254767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 31 loss 0.1013: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 31 loss 0.0904 c_acc 0.9048: 100%|██████████| 26/26 [00:01<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 train_loss 0.08258103228884169 eval_loss 1.296399373274583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 32 loss 0.1405: 100%|██████████| 101/101 [00:22<00:00,  4.48it/s]\n",
      "e 32 loss 0.3323 c_acc 0.9524: 100%|██████████| 26/26 [00:01<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 train_loss 0.07014604333308663 eval_loss 1.371297341126662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 33 loss 0.0289: 100%|██████████| 101/101 [00:22<00:00,  4.49it/s]\n",
      "e 33 loss 0.2815 c_acc 0.9048: 100%|██████████| 26/26 [00:01<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 train_loss 0.06643941046872942 eval_loss 1.265922601406391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t 34 loss 0.0643:   6%|▌         | 6/101 [00:01<00:26,  3.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26400/124817193.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26400/3978019171.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss = train_one_epoch(epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_loss = evaluate(epoch)\n",
    "\n",
    "    print(f\"epoch {epoch} train_loss {train_loss} eval_loss {eval_loss}\")\n",
    "\n",
    "    if wandb.run is not None:\n",
    "        wandb.log({\n",
    "            'average_train_loss' : train_loss,\n",
    "            'average_eval_loss' : eval_loss,\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
