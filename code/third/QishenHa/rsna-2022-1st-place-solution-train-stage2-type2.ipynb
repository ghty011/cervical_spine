{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1st Place Solution Training 2.5D Classification Type2\n",
    "\n",
    "Hi all,\n",
    "\n",
    "I'm very exciting to writing this notebook and the summary of our solution here.\n",
    "\n",
    "This is small version of training my final models (stage2 type2), using convnext nano as backbone, and 224x224 as input.\n",
    "\n",
    "After all stage1 models are trained, then we can use those model to predict 3D masks for all training samples (2k)\n",
    "\n",
    "Then use those predicted masks to crop out all vertebraes (2k * 7 = 14k)\n",
    "\n",
    "I'll skip the code of predicting 3D maks and cropping vertebraes, but just uploaded the dataset of cropped vertebraes (https://www.kaggle.com/datasets/haqishen/rsna-cropped-2d-224-0920-2m)\n",
    "\n",
    "Now let's use this dataset to train a 2.5D classification with LSTM (Type2)\n",
    "\n",
    "**NOTE: You should run it locally because it take too much GPU memory and RAM**\n",
    "\n",
    "To see more details of my solution: https://www.kaggle.com/competitions/rsna-2022-cervical-spine-fracture-detection/discussion/362607\n",
    "\n",
    "* Train Stage1 Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage1\n",
    "* Train Stage2 (Type1) Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-train-stage2-type1\n",
    "* Train Stage2 (Type2) Notebook: This notebook\n",
    "* Inference Notebook: https://www.kaggle.com/code/haqishen/rsna-2022-1st-place-solution-inference\n",
    "\n",
    "\n",
    "**If you find these notebooks helpful please upvote. Thanks! **"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip -q install timm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:07:39.043529Z",
     "iopub.execute_input": "2022-10-29T09:07:39.043973Z",
     "iopub.status.idle": "2022-10-29T09:07:51.472307Z",
     "shell.execute_reply.started": "2022-10-29T09:07:39.043892Z",
     "shell.execute_reply": "2022-10-29T09:07:51.471147Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DEBUG = False"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-10-29T09:07:51.476281Z",
     "iopub.execute_input": "2022-10-29T09:07:51.477957Z",
     "iopub.status.idle": "2022-10-29T09:07:51.482948Z",
     "shell.execute_reply.started": "2022-10-29T09:07:51.477911Z",
     "shell.execute_reply": "2022-10-29T09:07:51.481758Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import ast\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "import pickle\n",
    "import random\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import albumentations\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:07:51.486309Z",
     "iopub.execute_input": "2022-10-29T09:07:51.486622Z",
     "iopub.status.idle": "2022-10-29T09:07:55.619815Z",
     "shell.execute_reply.started": "2022-10-29T09:07:51.486587Z",
     "shell.execute_reply": "2022-10-29T09:07:55.618674Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "kernel_type = '0920_2d_lstmv22headv2_convnn_224_15_6ch_8flip_augv2_drl3_rov1p2_rov3p2_bs4_lr6e5_eta6e6_lw151_50ep'\n",
    "load_kernel = None\n",
    "load_last = True\n",
    "\n",
    "n_folds = 5\n",
    "backbone = 'convnext_nano'\n",
    "\n",
    "image_size = 224\n",
    "n_slice_per_c = 15\n",
    "in_chans = 6\n",
    "\n",
    "init_lr = 23e-5\n",
    "eta_min = 23e-6\n",
    "batch_size = 8\n",
    "drop_rate = 0.\n",
    "drop_rate_last = 0.3\n",
    "drop_path_rate = 0.\n",
    "p_mixup = 0.5\n",
    "p_rand_order = 0.2\n",
    "p_rand_order_v1 = 0.2\n",
    "\n",
    "data_dir = '../input/rsna-cropped-2d-224-0920-2m/cropped_2d_224_15_ext0_5ch_0920_2m/cropped_2d_224_15_ext0_5ch_0920_2m'\n",
    "use_amp = True\n",
    "num_workers = 4\n",
    "out_dim = 1\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "log_dir = './logs'\n",
    "model_dir = './models'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:50.228099Z",
     "iopub.execute_input": "2022-10-29T09:08:50.228479Z",
     "iopub.status.idle": "2022-10-29T09:08:50.237679Z",
     "shell.execute_reply.started": "2022-10-29T09:08:50.228447Z",
     "shell.execute_reply": "2022-10-29T09:08:50.235921Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "transforms_train = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.5),\n",
    "    albumentations.Transpose(p=0.5),\n",
    "    albumentations.RandomBrightness(limit=0.1, p=0.7),\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n",
    "\n",
    "    albumentations.OneOf([\n",
    "        albumentations.MotionBlur(blur_limit=3),\n",
    "        albumentations.MedianBlur(blur_limit=3),\n",
    "        albumentations.GaussianBlur(blur_limit=3),\n",
    "        albumentations.GaussNoise(var_limit=(3.0, 9.0)),\n",
    "    ], p=0.5),\n",
    "    albumentations.OneOf([\n",
    "        albumentations.OpticalDistortion(distort_limit=1.),\n",
    "        albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n",
    "    ], p=0.5),\n",
    "\n",
    "    albumentations.Cutout(max_h_size=int(image_size * 0.5), max_w_size=int(image_size * 0.5), num_holes=1, p=0.5),\n",
    "])\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(image_size, image_size),\n",
    "])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:51.018970Z",
     "iopub.execute_input": "2022-10-29T09:08:51.019330Z",
     "iopub.status.idle": "2022-10-29T09:08:51.028636Z",
     "shell.execute_reply.started": "2022-10-29T09:08:51.019300Z",
     "shell.execute_reply": "2022-10-29T09:08:51.027512Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../input/rsna-cropped-2d-224-0920-2m/train_seg.csv')\n",
    "df = df.sample(16).reset_index(drop=True) if DEBUG else df\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:51.858480Z",
     "iopub.execute_input": "2022-10-29T09:08:51.859289Z",
     "iopub.status.idle": "2022-10-29T09:08:51.886459Z",
     "shell.execute_reply.started": "2022-10-29T09:08:51.859244Z",
     "shell.execute_reply": "2022-10-29T09:08:51.885393Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class CLSDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        \n",
    "        images = []\n",
    "        \n",
    "        tmp = list(range(7))\n",
    "        ### random order v3\n",
    "        if self.mode == 'train' and random.random() < p_rand_order:\n",
    "            random.shuffle(tmp)\n",
    "        ###\n",
    "        for cid in (tmp):\n",
    "            for ind in list(range(n_slice_per_c)):\n",
    "                filepath = os.path.join(data_dir, f'{row.StudyInstanceUID}_{cid+1}_{ind}.npy')\n",
    "                image = np.load(filepath)\n",
    "                image = self.transform(image=image)['image']\n",
    "                image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n",
    "                images.append(image)\n",
    "        images = np.stack(images, 0)\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            labels = []\n",
    "            for i in row[[f'C{x+1}' for x in tmp]].tolist():\n",
    "                labels += [i] * n_slice_per_c\n",
    "            images = torch.tensor(images).float()\n",
    "            labels = torch.tensor(labels).float()\n",
    "            \n",
    "            if self.mode == 'train' and random.random() < p_rand_order_v1:\n",
    "                indices = torch.randperm(images.size(0))\n",
    "                images = images[indices]\n",
    "                labels = labels[indices]\n",
    "\n",
    "            return images, labels\n",
    "        else:\n",
    "            return torch.tensor(images).float()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:52.663996Z",
     "iopub.execute_input": "2022-10-29T09:08:52.664349Z",
     "iopub.status.idle": "2022-10-29T09:08:52.675444Z",
     "shell.execute_reply.started": "2022-10-29T09:08:52.664319Z",
     "shell.execute_reply": "2022-10-29T09:08:52.674271Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rcParams['figure.figsize'] = 20,8\n",
    "\n",
    "df_show = df\n",
    "dataset_show = CLSDataset(df_show, 'train', transform=transforms_train)\n",
    "loader_show = torch.utils.data.DataLoader(dataset_show, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:53.091585Z",
     "iopub.execute_input": "2022-10-29T09:08:53.094640Z",
     "iopub.status.idle": "2022-10-29T09:08:53.124930Z",
     "shell.execute_reply.started": "2022-10-29T09:08:53.094572Z",
     "shell.execute_reply": "2022-10-29T09:08:53.122780Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rcParams['figure.figsize'] = 16,8\n",
    "f, axarr = plt.subplots(2,4)\n",
    "for p in range(4):\n",
    "    idx = p * 20\n",
    "    imgs, lbl = dataset_show[idx]\n",
    "    axarr[0, p].imshow(imgs[35][:3].permute(1, 2, 0))\n",
    "    axarr[1, p].imshow(imgs[35][-1])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:08:54.117017Z",
     "iopub.execute_input": "2022-10-29T09:08:54.117601Z",
     "iopub.status.idle": "2022-10-29T09:09:03.269733Z",
     "shell.execute_reply.started": "2022-10-29T09:08:54.117548Z",
     "shell.execute_reply": "2022-10-29T09:09:03.268892Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class TimmModelType2(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super(TimmModelType2, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=in_chans,\n",
    "            num_classes=out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=drop_rate,\n",
    "            drop_path_rate=drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "\n",
    "        if 'efficient' in backbone:\n",
    "            hdim = self.encoder.conv_head.out_channels\n",
    "            self.encoder.classifier = nn.Identity()\n",
    "        elif 'convnext' in backbone:\n",
    "            hdim = self.encoder.head.fc.in_features\n",
    "            self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "        self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, out_dim),\n",
    "        )\n",
    "        self.lstm2 = nn.LSTM(hdim, 256, num_layers=2, dropout=drop_rate, bidirectional=True, batch_first=True)\n",
    "        self.head2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(drop_rate_last),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):  # (bs, nc*7, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * n_slice_per_c * 7, in_chans, image_size, image_size)\n",
    "        feat = self.encoder(x)\n",
    "        feat = feat.view(bs, n_slice_per_c * 7, -1)\n",
    "        feat1, _ = self.lstm(feat)\n",
    "        feat1 = feat1.contiguous().view(bs * n_slice_per_c * 7, 512)\n",
    "        feat2, _ = self.lstm2(feat)\n",
    "\n",
    "        return self.head(feat1), self.head2(feat2[:, 0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T09:09:24.700750Z",
     "iopub.execute_input": "2022-10-29T09:09:24.701871Z",
     "iopub.status.idle": "2022-10-29T09:09:24.715451Z",
     "shell.execute_reply.started": "2022-10-29T09:09:24.701808Z",
     "shell.execute_reply": "2022-10-29T09:09:24.714120Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss & Metric"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "\n",
    "def criterion(logits, targets, activated=False):\n",
    "    if activated:\n",
    "        losses = nn.BCELoss(reduction='none')(logits.view(-1), targets.view(-1))\n",
    "    else:\n",
    "        losses = bce(logits.view(-1), targets.view(-1))\n",
    "    losses[targets.view(-1) > 0] *= 2.\n",
    "    norm = torch.ones(logits.view(-1).shape[0]).to(device)\n",
    "    norm[targets.view(-1) > 0] *= 2\n",
    "    return losses.sum() / norm.sum()"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train & Valid func"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_loss1 = []\n",
    "    train_loss2 = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, targets in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        targets = targets.cuda()\n",
    "        \n",
    "        do_mixup = False\n",
    "        if random.random() < p_mixup:\n",
    "            do_mixup = True\n",
    "            images, targets, targets_mix, lam = mixup(images, targets)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits, logits2 = model(images)\n",
    "            loss1 = criterion(logits, targets)\n",
    "            loss2 = criterion(logits2, targets.max(1).values)\n",
    "            loss = (loss1 * lw[0] + loss2 * lw[1]) / sum(lw)\n",
    "            if do_mixup:\n",
    "                loss11 = criterion(logits, targets_mix)\n",
    "                loss22 = criterion(logits2, targets_mix.max(1).values)\n",
    "                loss = loss * lam  + (loss11 * lw[0] + loss22 * lw[1]) / sum(lw) * (1 - lam)\n",
    "        train_loss1.append(loss1.item())\n",
    "        train_loss2.append(loss2.item())\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bar.set_description(f'smth:{np.mean(train_loss1[-30:]):.4f} {np.mean(train_loss2[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    valid_loss1 = []\n",
    "    valid_loss2 = []\n",
    "    outputs = []\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, targets in bar:\n",
    "            images = images.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            logits, logits2 = model(images)\n",
    "            loss1 = criterion(logits, targets)\n",
    "            loss2 = criterion(logits2, targets.max(1).values)\n",
    "            loss = (loss1 + loss2) / 2.\n",
    "            valid_loss1.append(loss1.item())\n",
    "            valid_loss2.append(loss2.item())\n",
    "            valid_loss.append(loss.item())\n",
    "            bar.set_description(f'smth:{np.mean(valid_loss1[-30:]):.4f} {np.mean(valid_loss2[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(valid_loss)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T08:11:53.858143Z",
     "iopub.execute_input": "2022-10-29T08:11:53.858498Z",
     "iopub.status.idle": "2022-10-29T08:11:53.87108Z",
     "shell.execute_reply.started": "2022-10-29T08:11:53.858468Z",
     "shell.execute_reply": "2022-10-29T08:11:53.869966Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rcParams['figure.figsize'] = 20, 2\n",
    "optimizer = optim.AdamW(m.parameters(), lr=init_lr)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    scheduler_cosine.step(epoch-1)\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(range(len(lrs)), lrs)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T08:11:55.433782Z",
     "iopub.execute_input": "2022-10-29T08:11:55.434135Z",
     "iopub.status.idle": "2022-10-29T08:11:55.637241Z",
     "shell.execute_reply.started": "2022-10-29T08:11:55.434105Z",
     "shell.execute_reply": "2022-10-29T08:11:55.636298Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def run(fold):\n",
    "\n",
    "    log_file = os.path.join(log_dir, f'{kernel_type}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{kernel_type}_fold{fold}_best.pth')\n",
    "\n",
    "    train_ = df[df['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df[df['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = CLSDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = CLSDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    model = TimmModelType2(backbone, pretrained=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "    from_epoch = 0\n",
    "    metric_best = np.inf\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, n_epochs, eta_min=eta_min)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        scheduler_cosine.step(epoch-1)\n",
    "        if epoch < from_epoch + 1:\n",
    "            print(logs[epoch-1])\n",
    "            continue\n",
    "\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss = valid_func(model, loader_valid)\n",
    "        metric = valid_loss\n",
    "\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric < metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "#             if not DEBUG:\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T08:12:38.503102Z",
     "iopub.execute_input": "2022-10-29T08:12:38.503712Z",
     "iopub.status.idle": "2022-10-29T08:12:38.522409Z",
     "shell.execute_reply.started": "2022-10-29T08:12:38.503668Z",
     "shell.execute_reply": "2022-10-29T08:12:38.521354Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "run(0)\n",
    "run(1)\n",
    "run(2)\n",
    "run(3)\n",
    "run(4)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-29T08:12:42.821292Z",
     "iopub.execute_input": "2022-10-29T08:12:42.821672Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
