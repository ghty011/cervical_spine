{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 32\n",
    "wd = 1e-5\n",
    "pos_weight = 2\n",
    "image_size = 256\n",
    "# backbone=\"segmentation\"\n",
    "backbone=\"none\"\n",
    "vertical_type = \"sagittal\"\n",
    "train_portion = 0.5\n",
    "milestones = [50, 100, 150, 200]\n",
    "model_name = \"simple_resnet50\"\n",
    "\n",
    "slice_range=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "wandb_entity='longyi'\n",
    "\n",
    "wandb.init(project=\"cervical-spine\", entity=wandb_entity, config={\n",
    "    \"model\":model_name,\n",
    "    \"batch_size\":batch_size,\n",
    "    \"lr\" : lr,\n",
    "    \"wd\" : wd,\n",
    "    \"pos_weight\" : pos_weight,\n",
    "    \"backbone\" : backbone,\n",
    "    \"image_size\" : image_size,\n",
    "})\n",
    "wandb.run.name = f'{vertical_type}_{model_name}_c2_center_' + datetime.now().strftime(\"%H%M%S\")\n",
    "wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, CenterCrop\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pos_weight = torch.tensor(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = \"/media/longyi/SSD9701/\"\n",
    "# DATA_DIR = \"/Volumes/SSD970/\"\n",
    "DATA_DIR = \"/root/autodl-tmp/cervical_spine/\"\n",
    "TRAIN_IMAGES_DIR = os.path.join(DATA_DIR, \"train_images\")\n",
    "\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, f\"train_{vertical_type}_images_jpeg95\")\n",
    "LABEL_DIR = os.path.join(DATA_DIR, f\"segmentation_{vertical_type}_labels\")\n",
    "MASK_DIR = os.path.join(DATA_DIR, \"train_sagittal_labels_jpeg95\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_DIR, 'meta_sagittal_c2_center.csv')).set_index(\"UID\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = df[(df.C2 == 1) & (df.C2_cross_fracture == 1)]\n",
    "neg_df = df[(df.C2 == 0)]\n",
    "print(len(pos_df), len(neg_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pos_df, neg_df.iloc[:len(pos_df)]))\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class SagittalDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, mask_dir, transform=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) * slice_range\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.df.iloc[idx // 5]\n",
    "        UID = s.name\n",
    "        \n",
    "        center_slice = s.sagittal_center_slice + (idx % slice_range) - int(slice_range // 2)\n",
    "        \n",
    "        img = Image.open(os.path.join(self.image_dir, UID, f\"{center_slice}.jpeg\"))\n",
    "        img = TF.crop(img, s.top, s.left, s.bottom - s.top, s.right - s.left)\n",
    "\n",
    "        mask = Image.open(os.path.join(self.mask_dir, UID, f\"{center_slice}.png\"))\n",
    "\n",
    "        label = s.C2 & s.C2_cross_fracture\n",
    "\n",
    "        if self.transform:\n",
    "            img, mask, label = self.transform(img, mask, label)\n",
    "\n",
    "        return img, mask, label\n",
    "\n",
    "\n",
    "dataset = SagittalDataset(df, IMAGES_DIR, MASK_DIR)\n",
    "img, mask, label = dataset[20]\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(12, 12))\n",
    "print(label)\n",
    "axs[0].imshow(img, cmap='bone')\n",
    "\n",
    "axs[1].imshow(mask, cmap=\"nipy_spectral\")\n",
    "# axs[1].axhline(126)\n",
    "# axs[1].axvline(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class DataTransform(nn.Module):\n",
    "    def __init__(self, image_size, train=True):\n",
    "        super().__init__()\n",
    "        self.train = train\n",
    "       \n",
    "        transform = [T.Resize(image_size)]\n",
    "        if self.train:\n",
    "            transform.append(T.RandomAutocontrast())\n",
    "        \n",
    "        self.transform = T.Compose(transform + [\n",
    "            T.ToTensor(), \n",
    "            T.Normalize(0.5, 0.5)\n",
    "        ])\n",
    "\n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize(image_size, interpolation=torchvision.transforms.InterpolationMode.NEAREST),\n",
    "            T.PILToTensor(),\n",
    "            T.Lambda(lambda x: x.float()),\n",
    "            T.Normalize(0, 32)\n",
    "        ])\n",
    "\n",
    "        # self.label_transform = T.ToTensor()\n",
    "\n",
    "    def forward(self, x, mask, label):\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = TF.center_crop(x, max(x.width, x.height))\n",
    "        \n",
    "        if self.train:\n",
    "            random_rotation_angle = np.random.randint(-15, 15)\n",
    "            x = TF.rotate(x, random_rotation_angle)\n",
    "            mask = TF.rotate(mask, random_rotation_angle)\n",
    "        \n",
    "        \n",
    "        x = self.transform(x)\n",
    "\n",
    "        # print(mask)\n",
    "        mask = self.mask_transform(mask)\n",
    "        \n",
    "        # simple model\n",
    "        mask[mask != 0.25] = 0\n",
    "        mask[mask > 0] = 1\n",
    "\n",
    "        label = torch.tensor(label).long()\n",
    "        return x, mask, label\n",
    "\n",
    "\n",
    "transform = DataTransform(image_size)\n",
    "val_transform = DataTransform(image_size, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(df, train_portion=0.5):\n",
    "    df = shuffle(df)\n",
    "    train_end_index = int(len(df) * train_portion)\n",
    "    train_df = df.iloc[:train_end_index]\n",
    "    val_df = df.iloc[train_end_index:]\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_df, val_df = split_dataset(df, train_portion)\n",
    "print(len(train_df), len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = SagittalDataset(train_df, IMAGES_DIR, MASK_DIR, transform=transform)\n",
    "val_dataset = SagittalDataset(val_df, IMAGES_DIR, MASK_DIR, transform=val_transform)\n",
    "img, mask, label = train_dataset[1]\n",
    "print(img.shape)\n",
    "print(label)\n",
    "print(mask.shape)\n",
    "mask.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_backbone():\n",
    "    backbone = models.resnet50(pretrained=True)\n",
    "    conv1_weight = backbone.conv1.weight\n",
    "    conv1_weight = conv1_weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "    backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=1, padding='same', bias=False)\n",
    "    backbone.conv1.weight = nn.Parameter(conv1_weight, requires_grad=True)\n",
    "\n",
    "    return nn.ModuleList([\n",
    "        nn.Sequential(\n",
    "            backbone.conv1,\n",
    "            backbone.bn1,\n",
    "            backbone.relu,\n",
    "            backbone.maxpool),\n",
    "        nn.Sequential(\n",
    "            backbone.layer1,\n",
    "            backbone.layer2,\n",
    "        ),\n",
    "        backbone.layer3,\n",
    "        backbone.layer4\n",
    "    ]), [1, 64, 512, 1024, 2048]\n",
    "\n",
    "# backbone, channels = get_backbone()\n",
    "# print(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, backbone, channels, spine=2, deep=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.deep = deep\n",
    "        self.channels = channels\n",
    "        self.register_buffer('spine', torch.tensor(spine))\n",
    "        self.dw = nn.Parameter(torch.tensor(20.0, dtype=torch.float), requires_grad=False)\n",
    "        # self.register_buffer('mf', (torch.tensor(spine) * 0.125).reshape(1, 1, 1))\n",
    "        self.init_layers()\n",
    "\n",
    "    def init_layers(self):\n",
    "        self.parallel_modules_1 = self.make_parallel_modules()\n",
    "        self.parallel_modules_2 = self.make_parallel_modules()\n",
    "        self.downsampling_modules = self.make_downsampling_modules()\n",
    "        self.mask_modules = self.make_mask_modules()\n",
    "        self.classification_modules = self.make_classification_modules()\n",
    "\n",
    "    def make_parallel_modules(self):\n",
    "        parallel_modules = nn.ModuleList()\n",
    "\n",
    "        for channel in self.channels:\n",
    "            module = nn.Conv2d(channel, channel, kernel_size=1, padding='same')\n",
    "            parallel_modules.append(module)\n",
    "\n",
    "        return parallel_modules\n",
    "\n",
    "    def make_mask_modules(self):\n",
    "        mask_modules = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.deep):\n",
    "            module = nn.Sequential(\n",
    "                # nn.Conv2d(self.channels[i], self.channels[i+1], kernel_size=3, stride=2, padding=1),\n",
    "                # nn.Sigmoid()\n",
    "                nn.MaxPool2d(3, stride=2, padding=1)\n",
    "            )\n",
    "            mask_modules.append(module)\n",
    "\n",
    "        return mask_modules\n",
    "\n",
    "    def make_downsampling_modules(self):\n",
    "        downsampling_modules = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.deep):\n",
    "            module = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(self.channels[i], self.channels[i], kernel_size=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(self.channels[i], self.channels[i + 1], kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            )\n",
    "            downsampling_modules.append(module)\n",
    "\n",
    "        return downsampling_modules\n",
    "\n",
    "    def make_classification_modules(self):\n",
    "        return nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.channels[-1], self.channels[-1], kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.channels[-1] * 16 * 16, 1)\n",
    "        )\n",
    "\n",
    "    def forward_recursive(self, x, modules):\n",
    "        result = []\n",
    "        out = x\n",
    "        for module in modules:\n",
    "            out = module(out)\n",
    "            result.append(out)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def forward_parallel(self, inputs, modules):\n",
    "        result = []\n",
    "        for input, module in zip(inputs, modules):\n",
    "            out = module(input)\n",
    "            result.append(out)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def apply_mask(self, inputs, masks):\n",
    "        result = []\n",
    "\n",
    "        for input, mask in zip(inputs, masks):\n",
    "            out = input * mask\n",
    "            result.append(out)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def repeat_mask(self, mask):\n",
    "        N, H, W = mask.shape\n",
    "\n",
    "        mask[mask != (0.125 * self.spine)] = -torch.inf\n",
    "        # mask[mask == 0] = -torch.inf\n",
    "        #\n",
    "        mask  = mask.unsqueeze(1) ** 2\n",
    "        # mask = (mask.unsqueeze(1) - self.mf) ** 2\n",
    "        mask = torch.exp(-self.dw * mask)  # N, 7, H, W\n",
    "        # mask = mask.reshape(-1, 1, H, W) # N, 1, H, W\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def forward_downsampling(self, features, modules):\n",
    "        out = features[0]\n",
    "        for i, module in enumerate(modules):\n",
    "            out = module(out) + features[i + 1]\n",
    "\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # print(x)\n",
    "        backbone_features = self.forward_recursive(x, self.backbone)\n",
    "        # check_list_nan(backbone_features, \"backbone_features\")\n",
    "\n",
    "        mask = self.repeat_mask(mask)  # 14, 1, 256, 256\n",
    "        mask_features = self.forward_recursive(mask, self.mask_modules)\n",
    "\n",
    "        # check_list_nan(mask_features, \"mask_features\")\n",
    "\n",
    "        parallel_features_1 = self.forward_parallel([x] + backbone_features, self.parallel_modules_1)\n",
    "        # 여기서 뻥튀기를 시킨다.\n",
    "        # parallel_features_1 = [feature.repeat_interleave(self.mf.shape[0], dim=0) for feature in parallel_features_1]\n",
    "\n",
    "        # check_list_nan(parallel_features_1)\n",
    "\n",
    "        masked_features = self.apply_mask(parallel_features_1, [mask] + mask_features)\n",
    "\n",
    "        # check_list_nan(masked_features)\n",
    "        out = self.forward_parallel(masked_features, self.parallel_modules_2)\n",
    "\n",
    "        # check_list_nan(out)\n",
    "        out = self.forward_downsampling(out, self.downsampling_modules)\n",
    "        out = self.classification_modules(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# model = ClassificationModel(backbone, channels).to(device)\n",
    "#\n",
    "# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(total_params)\n",
    "\n",
    "# input = torch.randn(2, 1, 256, 256).to(device)\n",
    "# mask = torch.randn(2, 256, 256).to(device)\n",
    "# logits = model(input, mask)\n",
    "# logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_resnet_model():\n",
    "    backbone = models.resnet50(pretrained=True)\n",
    "    conv1_weight = backbone.conv1.weight\n",
    "    conv1_weight = conv1_weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "    backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=1, padding='same', bias=False)\n",
    "    backbone.conv1.weight = nn.Parameter(conv1_weight, requires_grad=True)\n",
    "    \n",
    "    backbone.fc = nn.Sequential(\n",
    "        nn.Linear(2048, 512, bias=True),\n",
    "        nn.Linear(512, 1, bias=True),\n",
    "    )\n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=False, num_workers=min(16, batch_size))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=min(16, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, mask, y = next(iter(val_loader))\n",
    "print(y)\n",
    "sample_index = 11\n",
    "\n",
    "print(\"label {}\".format(y[sample_index]))\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(12, 12))\n",
    "\n",
    "axs[0].imshow(mask[sample_index, 0, :, :])\n",
    "axs[1].imshow((x * mask)[sample_index, 0, :, :], cmap='bone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(logits, y, pos_weight=torch.tensor(1)):\n",
    "    # labels = F.one_hot(y, num_classes=7).reshape(-1, 1).float()\n",
    "\n",
    "    loss = F.binary_cross_entropy_with_logits(logits, y, pos_weight=pos_weight)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def denormalize_img(x):\n",
    "    img = x.detach().cpu().numpy()\n",
    "    img = (img * 0.5) + 0.5\n",
    "    img = img.transpose(0, 2, 3, 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionModel(nn.Module):\n",
    "    def __init__(self, backbone, channels, deep=4, out_channels=64, n_features=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.deep = deep\n",
    "        self.channels = channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_features = n_features\n",
    "\n",
    "        self.init_layers()\n",
    "\n",
    "    def init_layers(self):\n",
    "        self.parallel_modules = self.make_parallel_modules()\n",
    "        self.upsampling_modules = self.make_upsampling_modules()\n",
    "\n",
    "        self.downsampling_modules = self.make_downsampling_modules()\n",
    "        self.classification_modules = self.make_classification_modules()\n",
    "\n",
    "    def make_classification_modules(self):\n",
    "        # the last layer\n",
    "        return nn.Sequential(\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(self.out_channels, 2 * self.out_channels, kernel_size=3, padding='same'),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(2 * self.out_channels, self.n_features, kernel_size=1, padding='same'),\n",
    "        )\n",
    "\n",
    "    def make_parallel_modules(self):\n",
    "        parallel_modules = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.deep):\n",
    "            module = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(self.channels[i], self.channels[i], kernel_size=3, padding='same'),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(self.channels[i], self.channels[i], kernel_size=1, padding='same'),\n",
    "            )\n",
    "            parallel_modules.append(module)\n",
    "\n",
    "        return parallel_modules\n",
    "\n",
    "    def make_downsampling_modules(self):\n",
    "        return nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                self.backbone.conv1,\n",
    "                self.backbone.bn1,\n",
    "                self.backbone.relu,\n",
    "                self.backbone.maxpool),\n",
    "            nn.Sequential(\n",
    "                self.backbone.layer1,\n",
    "                self.backbone.layer2,\n",
    "            ),\n",
    "            self.backbone.layer3,\n",
    "            self.backbone.layer4\n",
    "        ])\n",
    "\n",
    "    def make_upsampling_modules(self):\n",
    "        upsampling_modules = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.deep):\n",
    "            module = nn.Sequential(\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(self.channels[i], self.channels[i] // 2, kernel_size=3, padding='same'),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(self.channels[i] // 2, self.channels[i - 1] if i > 0 else self.out_channels, kernel_size=1),\n",
    "                nn.Upsample(scale_factor=2)\n",
    "            )\n",
    "            upsampling_modules.append(module)\n",
    "\n",
    "        return upsampling_modules\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        downsampling_outputs = []\n",
    "        out = x\n",
    "        for module in self.downsampling_modules:\n",
    "            out = module(out)\n",
    "            downsampling_outputs.append(out)\n",
    "\n",
    "        parallel_outputs = []\n",
    "        for i in range(len(self.parallel_modules)):\n",
    "            module = self.parallel_modules[i]\n",
    "            out = module(downsampling_outputs[i])\n",
    "            parallel_outputs.append(out)\n",
    "\n",
    "        out = 0\n",
    "        for i in range(len(self.upsampling_modules)):\n",
    "            module = self.upsampling_modules[-(i + 1)]\n",
    "            parallel_output = parallel_outputs[-(i + 1)]\n",
    "\n",
    "            up_input = out + parallel_output\n",
    "            out = module(up_input)\n",
    "\n",
    "        out = self.classification_modules(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def get_seg_backbone():\n",
    "    backbone = models.resnet50(pretrained=False)\n",
    "    conv1_weight = backbone.conv1.weight\n",
    "    conv1_weight = conv1_weight.mean(dim=1).unsqueeze(1)\n",
    "\n",
    "    backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=1, padding='same', bias=False)\n",
    "    backbone.conv1.weight = nn.Parameter(conv1_weight, requires_grad=True)\n",
    "\n",
    "    channels = [64, 512, 1024, 2048]\n",
    "    checkpoint = f\"checkpoint/{vertical_type}_segmentation_detection_095730-epoch-20.pth\"\n",
    "    seg_model = DetectionModel(backbone, channels=channels, out_channels=channels[0], n_features=2).to(device)\n",
    "    state = torch.load(checkpoint)\n",
    "    seg_model.load_state_dict(state[\"model\"])\n",
    "    return seg_model.downsampling_modules, [1, 64, 512, 1024, 2048]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# backbone, channels = get_backbone()\n",
    "# if backbone == \"segmentation\":\n",
    "#     backbone, channels = get_seg_backbone()\n",
    "# else:\n",
    "#     backbone, channels = get_backbone()\n",
    "# model = ClassificationModel(backbone, channels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_simple_resnet_model()\n",
    "model = model.to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_batch_size=16\n",
    "\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=min(16, batch_size))\n",
    "\n",
    "# test_loader = DataLoader(val_dataset, batch_size=test_batch_size, shuffle=False, pin_memory=False, num_workers=test_batch_size)\n",
    "# val_iter = iter(val_loader)\n",
    "x, mask, y = next(iter(val_loader))\n",
    "print(y)\n",
    "x = x.to(device)\n",
    "mask = mask.to(device)\n",
    "x = x * mask\n",
    "# mask = mask.to(device)\n",
    "y = y.to(device).float()\n",
    "\n",
    "logits = model(x).flatten()\n",
    "loss = loss_fn(logits, y, pos_weight=torch.tensor(2))\n",
    "print(loss.item())\n",
    "pred = logits.sigmoid().ge(0.5).float()\n",
    "print(y)\n",
    "print(pred)\n",
    "acc = (pred == y).float().mean()\n",
    "print(acc)\n",
    "\n",
    "del x\n",
    "del mask\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device == 'cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_mask(x, mask):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(e, model, dataloader):\n",
    "    model.train()\n",
    "    train_iter = tqdm(dataloader)\n",
    "    losses = []\n",
    "    epoch_iteration = len(dataloader)\n",
    "\n",
    "    for i, (x, mask, y) in enumerate(train_iter):\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        x = x * mask\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        with torch.cuda.amp.autocast(device == 'cuda'):\n",
    "            logits = model(x).flatten()\n",
    "            loss = loss_fn(logits, y, pos_weight=pos_weight)\n",
    "            acc = (logits.sigmoid().ge(0.5).float() == y).float().mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_iter.set_description(f\"t {e} loss {loss.item():.4f} acc {acc.item():.4f}\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            lr_logs = {f\"last_lr_{i}\": float(v) for i, v in enumerate(scheduler.get_last_lr())}\n",
    "            wandb.log({\n",
    "                'train_loss': loss.item(),\n",
    "                'train_acc' : acc.item(),\n",
    "                'epoch': e,\n",
    "                'train_iteration': i + e * epoch_iteration,\n",
    "                **lr_logs,\n",
    "            })\n",
    "\n",
    "        # if i % 10 == 0:\n",
    "        #     with torch.no_grad():\n",
    "        #         infer_bad_sample(wandb_log=True)\n",
    "        #     model.train()\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(e, model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_iter = tqdm(dataloader)\n",
    "    losses = []\n",
    "    epoch_iteration = len(dataloader)\n",
    "    \n",
    "    eps = 1e-3\n",
    "\n",
    "    for i, (x, mask, y) in enumerate(eval_iter):\n",
    "        x = x.to(device)\n",
    "        mask = mask.to(device)\n",
    "        x = x * mask\n",
    "        # mask = mask.to(device)\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        with torch.cuda.amp.autocast(device == 'cuda'):\n",
    "            logits = model(x).flatten()\n",
    "            prob = logits.sigmoid()\n",
    "            prob = prob.clip(min=eps, max=(1 - eps))\n",
    "            loss = F.binary_cross_entropy(prob, y)\n",
    "            pred = prob.ge(0.5).float()\n",
    "            \n",
    "            acc = (pred == y).float().mean()\n",
    "\n",
    "        eval_iter.set_description(f\"e {e} loss {loss.item():.4f} ecc {acc.item():.4f}\")\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'eval_loss': loss.item(),\n",
    "                'eval_acc' : acc.item(),\n",
    "                'epoch': e,\n",
    "                'eval_iteration': i + e * epoch_iteration,\n",
    "            })\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "\n",
    "evaluate(epoch, model, val_loader)\n",
    "\n",
    "for e in range(epochs):\n",
    "\n",
    "    train_loss = train_one_epoch(epoch, model, train_loader)\n",
    "    \n",
    "    eval_loss = evaluate(epoch, model, val_loader)\n",
    "    \n",
    "    print(f\"train loss {train_loss} eval loss {eval_loss}\")\n",
    "    scheduler.step()\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# state = {\n",
    "#     \"model\": model.state_dict(),\n",
    "#     \"optimizer\": optimizer.state_dict(),\n",
    "#     \"scheduler\": scheduler.state_dict(),\n",
    "#     \"epoch\": epoch,\n",
    "# }\n",
    "# torch.save(state, f'checkpoint/{wandb.run.name}-epoch-{epoch}.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
