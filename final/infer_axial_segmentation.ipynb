{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a641e3d-4b38-4d70-9fa0-e80ed1f32d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'axial_segmentation_effseg_095521-epoch-61.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a4aafb-f48b-4801-ade7-4e8a21d00e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e8b50-fa90-4bd6-a22e-25c84608ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize, CenterCrop\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406541a8-f01a-4fdb-84d7-aca3ac79a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/root/autodl-tmp/cervical_spine/\"\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, f\"train_axial_images_jpeg95\")\n",
    "LABEL_DIR = os.path.join(DATA_DIR, f\"segmentation_axial_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5e047e-b44a-45e2-8269-83e8580b5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientunet import *\n",
    "\n",
    "def get_axial_segmentation_model(checkpoint):\n",
    "    model = get_efficientunet_b5(out_channels=2, concat_input=True, pretrained=True)\n",
    "    \n",
    "    state = torch.load(os.path.join(DATA_DIR, 'checkpoint', checkpoint))\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "    return model.to(device)\n",
    "    \n",
    "model = get_axial_segmentation_model(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4a60f-8f25-4fa5-80be-662b72694aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "UID = '1.2.826.0.1.3680043.1636'\n",
    "# axial_index = 205\n",
    "# label = Image.open(os.path.join(LABEL_DIR, UID, f\"{axial_index}.png\"))\n",
    "# label = np.array(label) / 256\n",
    "\n",
    "# print(label.min(), label.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3184c36-4b4a-4015-97c5-9ed9be7c7450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox_class(label, bbox):\n",
    "    \"\"\"\n",
    "    label 은 0.125 의 단위로, \n",
    "    bbox: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox\n",
    "    area = label[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    plt.imshow(label)\n",
    "    plt.axvline(xmin)\n",
    "    plt.axvline(xmax)\n",
    "    plt.axhline(ymin)\n",
    "    plt.axhline(ymax)\n",
    "    # print(area)\n",
    "    result = np.mean(area[area>0])\n",
    "    result = np.round(result / 0.125)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# get_bbox_class(label, [270, 180, 320, 190])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f509c8-4d48-42d4-8ef4-39a0d515e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axial_boundary(seg, pixel_spacing, throw=100, tol=0.2, max_mm=100):\n",
    "    image_size = seg.shape[0]\n",
    "    min_size = min(image_size, max_mm / pixel_spacing)\n",
    "    \n",
    "    rows, columns = seg.nonzero()\n",
    "    rows.sort()\n",
    "    columns.sort()\n",
    "    \n",
    "    throw = min(len(rows) // 2, throw)\n",
    "    \n",
    "    if(len(rows)) == 0:\n",
    "        return 0, 0, image_size, image_size\n",
    "    \n",
    "    xmin, xmax = columns[throw], columns[-throw]\n",
    "    ymin, ymax = rows[throw], rows[-throw]\n",
    "    \n",
    "    w = (xmax - xmin) * (1 + tol)\n",
    "    h = (ymax - ymax) * (1 + tol)\n",
    "    new_size = max(w, h, min_size)\n",
    "    new_size = min(image_size, new_size)\n",
    "    \n",
    "    xcenter, ycenter = (xmax + xmin) / 2, (ymax + ymin) / 2\n",
    "    \n",
    "    xmin = min(image_size - new_size, xcenter - new_size / 2)\n",
    "    xmin = max(0, xmin)\n",
    "    \n",
    "    ymin = min(image_size - new_size, ycenter - new_size / 2)\n",
    "    ymin = max(0, ymin)\n",
    "    \n",
    "    return xmin, ymin, xmin + new_size, ymin + new_size\n",
    "\n",
    "# UID = '1.2.826.0.1.3680043.10062'\n",
    "\n",
    "\n",
    "# _, axs = plt.subplots(28, 10, figsize=(100, 280))\n",
    "\n",
    "# for i in range(280):\n",
    "    \n",
    "#     axial_index = i\n",
    "#     label = Image.open(os.path.join(LABEL_DIR, UID, f\"{axial_index}.png\"))\n",
    "#     label = np.array(label) / 256\n",
    "#     xmin, ymin, xmax, ymax = get_axial_boundary(label, 0.2539)\n",
    "#     axs[i//10, i % 10].imshow(label)\n",
    "#     axs[i//10, i % 10].axvline(xmin)\n",
    "#     axs[i//10, i % 10].axvline(xmax)\n",
    "#     axs[i//10, i % 10].axhline(ymin)\n",
    "#     axs[i//10, i % 10].axhline(ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688173f0-3dfe-4aff-a28f-ae03fb0fdde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "\n",
    "        \n",
    "        self.transform = A.Compose([\n",
    "            A.Resize(image_size, image_size),\n",
    "            ToTensorV2(p=1),\n",
    "        ])\n",
    "\n",
    "        self.normalize = T.Normalize(255 * 0.5, 255 * 0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        augmented = self.transform(image=np.asarray(x))\n",
    "        x= augmented['image']\n",
    "\n",
    "        x = self.normalize(x.float())\n",
    "\n",
    "        return x\n",
    "    \n",
    "transform = DataTransform(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c046fe3f-20ce-44a6-84e3-2c17d877ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(x, model):\n",
    "    x = x.to(device)\n",
    "    logits = model(x)\n",
    "\n",
    "    classification_score, mse_score = logits.sigmoid().chunk(2, dim=1)\n",
    "    classification_pred = classification_score.gt(0.5).float()\n",
    "    pred = (classification_pred * mse_score).cpu().numpy()\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9e578-76b8-472b-93e3-c91fb74726c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = Image.open(os.path.join(IMAGES_DIR, UID, '156.jpeg'))\n",
    "# x = transform(img).unsqueeze(0).to(device)\n",
    "# print(x.min(), x.max())\n",
    "# print(x.shape)\n",
    "# label = predict(x, model)\n",
    "# print(label.min(), label.max())\n",
    "\n",
    "# plt.imshow(label.squeeze())\n",
    "# get_axial_boundary(label.squeeze(), 0.327, throw=50, tol=0.2, max_mm=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c48840-b084-4dd1-b189-d2ff1f0fdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3d_df = pd.read_csv(os.path.join(DATA_DIR, 'meta_train_3d.csv')).set_index('UID')\n",
    "print(len(train_3d_df))\n",
    "train_3d_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c0895-5c00-4418-a673-303a4c36f581",
   "metadata": {},
   "outputs": [],
   "source": [
    "UID = '1.2.826.0.1.3680043.15105'\n",
    "# UID = '1.2.826.0.1.3680043.15206'\n",
    "pixel_spacing = float(train_3d_df.loc[UID, 'pixel_spacing'])\n",
    "\n",
    "_, axs = plt.subplots(28, 10, figsize=(100, 280))\n",
    "\n",
    "class_label_list = []\n",
    "\n",
    "for i in tqdm(range(280)):\n",
    "    \n",
    "    index = i\n",
    "    rpath = os.path.join(IMAGES_DIR, UID, f\"{index-2}.jpeg\")\n",
    "    gpath = os.path.join(IMAGES_DIR, UID, f\"{index-1}.jpeg\")\n",
    "    bpath = os.path.join(IMAGES_DIR, UID, f\"{index}.jpeg\")\n",
    "    r = Image.open(rpath) if os.path.exists(rpath) else Image.open(bpath)\n",
    "    g = Image.open(gpath) if os.path.exists(gpath) else Image.open(bpath)\n",
    "    b = Image.open(bpath) \n",
    "    \n",
    "    img = Image.merge(\"RGB\",(r,g,b))\n",
    "    # print(np.asarray(img).shape)\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    # print(x.shape)\n",
    "    # break\n",
    "    \n",
    "    label = predict(x, model)\n",
    "    label = np.round(label / 0.125) * 0.125\n",
    "    label = label.squeeze()\n",
    "    class_label = np.mean(label[label > 0])\n",
    "    class_label_list.append(class_label)\n",
    "    xmin, ymin, xmax, ymax = get_axial_boundary(label, pixel_spacing, throw=50, tol=0.2, max_mm=50)\n",
    "    axs[i//10, i % 10].imshow(label, cmap='nipy_spectral')\n",
    "    axs[i//10, i % 10].axvline(xmin)\n",
    "    axs[i//10, i % 10].axvline(xmax)\n",
    "    axs[i//10, i % 10].axhline(ymin)\n",
    "    axs[i//10, i % 10].axhline(ymax)\n",
    "    axs[i//10, i % 10].set_title(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4107ea9d-f65f-47cb-9f3c-ba00cb4182cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(class_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db4575-bd35-45b9-8c0a-b79b1adce96e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
