{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b91dbef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:09:59.471238Z",
     "iopub.status.busy": "2022-10-17T23:09:59.470776Z",
     "iopub.status.idle": "2022-10-17T23:12:32.915620Z",
     "shell.execute_reply": "2022-10-17T23:12:32.914146Z"
    },
    "papermill": {
     "duration": 153.456956,
     "end_time": "2022-10-17T23:12:32.918639",
     "exception": false,
     "start_time": "2022-10-17T23:09:59.461683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/effdet-models/pydicom-2.3.0-py3-none-any.whl\n",
      "pydicom is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /kaggle/input/effdet-models/pylibjpeg-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pylibjpeg==1.4.0) (1.21.6)\n",
      "Installing collected packages: pylibjpeg\n",
      "Successfully installed pylibjpeg-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /kaggle/input/effdet-models/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from pylibjpeg-libjpeg==1.3.2) (1.21.6)\n",
      "Installing collected packages: pylibjpeg-libjpeg\n",
      "Successfully installed pylibjpeg-libjpeg-1.3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /kaggle/input/effdet-models/python_gdcm-3.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: python-gdcm\n",
      "Successfully installed python-gdcm-3.0.19\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mProcessing /kaggle/input/effdet-models/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (3.5.3)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (59.8.0)\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools==2.0.2) (0.29.32)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (9.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2) (1.4.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.0->pycocotools==2.0.2) (4.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.2) (1.15.0)\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import pylibjpeg\n",
    "except:\n",
    "    !mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "    !cp ../input/effdet-models/efficientnet_v2s_ra2_288-a6477665.pth /root/.cache/torch/hub/checkpoints/\n",
    "    !pip install ../input/effdet-models/pydicom-2.3.0-py3-none-any.whl\n",
    "    !pip install ../input/effdet-models/pylibjpeg-1.4.0-py3-none-any.whl\n",
    "    !pip install ../input/effdet-models/pylibjpeg_libjpeg-1.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "    !pip install ../input/effdet-models/python_gdcm-3.0.19-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "    !pip install ../input/effdet-models/pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17fcf25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:32.935154Z",
     "iopub.status.busy": "2022-10-17T23:12:32.934142Z",
     "iopub.status.idle": "2022-10-17T23:12:36.987753Z",
     "shell.execute_reply": "2022-10-17T23:12:36.986768Z"
    },
    "papermill": {
     "duration": 4.064069,
     "end_time": "2022-10-17T23:12:36.990186",
     "exception": false,
     "start_time": "2022-10-17T23:12:32.926117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import ast\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import pydicom as dicom\n",
    "import pylibjpeg\n",
    "\n",
    "effdet_path = \"../input/effdet-models/effdet\"\n",
    "sys.path.append(effdet_path)\n",
    "\n",
    "\n",
    "timm_path = \"../input/effdet-models/timm-pytorch-image-models\"\n",
    "sys.path.append(timm_path)\n",
    "import timm\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import matplotlib.pyplot as plt\n",
    "# from matplotlib import patches\n",
    "# import sklearn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "omega_path = \"../input/effdet-models/omegaconf\"\n",
    "sys.path.append(omega_path)\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "effunet_path = \"../input/effdet-models/efficientunet-pytorch-0.0.6\"\n",
    "sys.path.append(effunet_path)\n",
    "\n",
    "# from effdet import create_model\n",
    "\n",
    "import glob\n",
    "# import sklearn\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "# import cv2\n",
    "# import albumentations as A\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "# from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "# pos_weight = torch.tensor(pos_weight)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d906cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.006380Z",
     "iopub.status.busy": "2022-10-17T23:12:37.005615Z",
     "iopub.status.idle": "2022-10-17T23:12:37.010453Z",
     "shell.execute_reply": "2022-10-17T23:12:37.009474Z"
    },
    "papermill": {
     "duration": 0.01514,
     "end_time": "2022-10-17T23:12:37.012445",
     "exception": false,
     "start_time": "2022-10-17T23:12:36.997305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGES_DIR='../input/rsna-2022-cervical-spine-fracture-detection/test_images'\n",
    "TRAIN_IMAGES_PATH='../input/rsna-2022-cervical-spine-fracture-detection/train_images'\n",
    "TEST_IMAGES_PATH='../input/rsna-2022-cervical-spine-fracture-detection/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243ff9ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.028005Z",
     "iopub.status.busy": "2022-10-17T23:12:37.027725Z",
     "iopub.status.idle": "2022-10-17T23:12:37.032863Z",
     "shell.execute_reply": "2022-10-17T23:12:37.032047Z"
    },
    "papermill": {
     "duration": 0.01553,
     "end_time": "2022-10-17T23:12:37.034910",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.019380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "segmentation_checkpoint=\"../input/effdet-models/axial_segmentation_effseg_132508-epoch-100.pth\"\n",
    "axial_det_checkpoint=\"../input/effdet-models/axial_detection_effdet_134352-epoch-52.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6279a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.051088Z",
     "iopub.status.busy": "2022-10-17T23:12:37.050830Z",
     "iopub.status.idle": "2022-10-17T23:12:37.164869Z",
     "shell.execute_reply": "2022-10-17T23:12:37.163981Z"
    },
    "papermill": {
     "duration": 0.125074,
     "end_time": "2022-10-17T23:12:37.167059",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.041985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1318 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               StudyInstanceUID  Slice\n",
       "0     1.2.826.0.1.3680043.22327      1\n",
       "1     1.2.826.0.1.3680043.22327      2\n",
       "2     1.2.826.0.1.3680043.22327      3\n",
       "3     1.2.826.0.1.3680043.22327      4\n",
       "4     1.2.826.0.1.3680043.22327      5\n",
       "...                         ...    ...\n",
       "1313   1.2.826.0.1.3680043.5876    454\n",
       "1314   1.2.826.0.1.3680043.5876    455\n",
       "1315   1.2.826.0.1.3680043.5876    456\n",
       "1316   1.2.826.0.1.3680043.5876    457\n",
       "1317   1.2.826.0.1.3680043.5876    458\n",
       "\n",
       "[1318 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test, use these\n",
    "# train_df = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/train.csv').set_index('StudyInstanceUID')\n",
    "# train_df.head()\n",
    "\n",
    "\n",
    "# IMAGES_DIR='../input/rsna-2022-cervical-spine-fracture-detection/train_images'\n",
    "# TRAIN_IMAGES_PATH='../input/rsna-2022-cervical-spine-fracture-detection/train_images'\n",
    "# TEST_IMAGES_PATH='../input/rsna-2022-cervical-spine-fracture-detection/test_images'\n",
    "\n",
    "\n",
    "# test_slices = glob.glob(f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.18*/*')\n",
    "# test_slices = [re.findall(f'{TRAIN_IMAGES_PATH}/(.*)/(.*).dcm', s)[0] for s in test_slices]\n",
    "# df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice']).astype({'Slice': int}).sort_values(['StudyInstanceUID', 'Slice']).reset_index(drop=True)\n",
    "# df_test_slices\n",
    "# test end\n",
    "\n",
    "test_slices = glob.glob(f'{TEST_IMAGES_PATH}/*/*')\n",
    "test_slices = [re.findall(f'{TEST_IMAGES_PATH}/(.*)/(.*).dcm', s)[0] for s in test_slices]\n",
    "df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice']).astype({'Slice': int}).sort_values(['StudyInstanceUID', 'Slice']).reset_index(drop=True)\n",
    "df_test_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9751a21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.182452Z",
     "iopub.status.busy": "2022-10-17T23:12:37.182164Z",
     "iopub.status.idle": "2022-10-17T23:12:37.189231Z",
     "shell.execute_reply": "2022-10-17T23:12:37.188364Z"
    },
    "papermill": {
     "duration": 0.017263,
     "end_time": "2022-10-17T23:12:37.191371",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.174108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rescale_img_to_hu(dcm_ds):\n",
    "    \"\"\"Rescales the image to Hounsfield unit.\n",
    "    \"\"\"\n",
    "    return dcm_ds.pixel_array * dcm_ds.RescaleSlope + dcm_ds.RescaleIntercept\n",
    "\n",
    "def normalize_hu(data):\n",
    "    # normalize to 0-1\n",
    "    # return (data - data.min()) / data.max()\n",
    "    data = np.clip(data, a_min=-2242, a_max=2242) / 4484 + 0.5\n",
    "    return data\n",
    "\n",
    "def load_dicom(path):\n",
    "    \"\"\"\n",
    "    This supports loading both regular and compressed JPEG images. \n",
    "    See the first sell with `pip install` commands for the necessary dependencies\n",
    "    \"\"\"\n",
    "    ds=dicom.dcmread(path) \n",
    "\n",
    "#     img = normalize_hu(rescale_img_to_hu(ds))\n",
    "    img = rescale_img_to_hu(ds)\n",
    "\n",
    "    return img, ds.PixelSpacing[0]\n",
    "\n",
    "# im, pixel_spacing = load_dicom(f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10001/1.dcm')\n",
    "# print(pixel_spacing)\n",
    "# print(im.shape)\n",
    "# print(im.min(), im.max())\n",
    "# print(torch.as_tensor(im).shape)\n",
    "# plt.figure()\n",
    "# plt.imshow(im)\n",
    "# plt.title('regular image')\n",
    "\n",
    "# im, meta = load_dicom(f'{TRAIN_IMAGES_PATH}/1.2.826.0.1.3680043.10014/1.dcm')\n",
    "# plt.figure()\n",
    "# plt.imshow(im)\n",
    "# plt.title('jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a82ea72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.207098Z",
     "iopub.status.busy": "2022-10-17T23:12:37.206845Z",
     "iopub.status.idle": "2022-10-17T23:12:37.279814Z",
     "shell.execute_reply": "2022-10-17T23:12:37.277685Z"
    },
    "papermill": {
     "duration": 0.084026,
     "end_time": "2022-10-17T23:12:37.282765",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.198739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 512, 512])\n",
      "tensor(-0.9135) tensor(0.9692)\n",
      "0.384766\n"
     ]
    }
   ],
   "source": [
    "class DcmDataSet(torch.utils.data.Dataset):    \n",
    "    def __init__(self, df, path, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.len = len(self.df)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "              \n",
    "        \n",
    "        try:\n",
    "            s = self.df.iloc[i]\n",
    "            prev_s = self.df.iloc[i-1] if i > 0 else s\n",
    "            prev_s = s if prev_s.StudyInstanceUID != s.StudyInstanceUID else prev_s\n",
    "            \n",
    "            next_s = self.df.iloc[i+1] if i < (self.len-1) else s\n",
    "            next_s = s if next_s.StudyInstanceUID != s.StudyInstanceUID else next_s\n",
    "            \n",
    "#             slice = s.Slice\n",
    "            rpath = os.path.join(self.path, s.StudyInstanceUID, f'{prev_s.Slice}.dcm')\n",
    "            gpath = os.path.join(self.path, s.StudyInstanceUID, f'{s.Slice}.dcm')\n",
    "            bpath = os.path.join(self.path, s.StudyInstanceUID, f'{next_s.Slice}.dcm')\n",
    "            \n",
    "#             print(rpath)\n",
    "#             print(os.path.exists(rpath))\n",
    "            \n",
    "            g, pixel_spacing = load_dicom(gpath) \n",
    "            r, _ = load_dicom(rpath)\n",
    "            b, _ = load_dicom(bpath)\n",
    "            \n",
    "#             print(r.shape)\n",
    "#             print(g.shape)\n",
    "#             print(b.shape)\n",
    "            img = np.stack((r, g, b))\n",
    "            img = normalize_hu(img)\n",
    "#             print(img.shape)\n",
    "#             img = np.transpose(img, (2, 0, 1))  # Pytorch uses (batch, channel, height, width) order. Converting (height, width, channel) -> (channel, height, width)\n",
    "            if self.transforms is not None:\n",
    "                img = self.transforms(img)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            return None, None\n",
    "        \n",
    "        return img, pixel_spacing      \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class DataTransform(nn.Module):\n",
    "    def __init__(self, image_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.Normalize(0.5, 0.5),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transform(torch.as_tensor(x, dtype=torch.float))\n",
    "\n",
    "        return x\n",
    "\n",
    "tf = DataTransform()\n",
    "ds = DcmDataSet(df_test_slices, IMAGES_DIR, tf)\n",
    "input, pixel_spacing = ds[0]\n",
    "print(input.shape)\n",
    "print(input.min(), input.max())\n",
    "print(pixel_spacing)\n",
    "\n",
    "# plt.imshow(input.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b47241f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.299942Z",
     "iopub.status.busy": "2022-10-17T23:12:37.299046Z",
     "iopub.status.idle": "2022-10-17T23:12:37.304348Z",
     "shell.execute_reply": "2022-10-17T23:12:37.303510Z"
    },
    "papermill": {
     "duration": 0.015545,
     "end_time": "2022-10-17T23:12:37.306512",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.290967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=min(os.cpu_count(), batch_size))\n",
    "\n",
    "# x, pixel_spacings = next(iter(dl))\n",
    "# print(x.shape)\n",
    "# print(pixel_spacings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c57ff08f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:37.321785Z",
     "iopub.status.busy": "2022-10-17T23:12:37.321517Z",
     "iopub.status.idle": "2022-10-17T23:12:46.431522Z",
     "shell.execute_reply": "2022-10-17T23:12:46.430431Z"
    },
    "papermill": {
     "duration": 9.121351,
     "end_time": "2022-10-17T23:12:46.434785",
     "exception": false,
     "start_time": "2022-10-17T23:12:37.313434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from efficientunet import *\n",
    "def get_axial_segmentation_model(checkpoint):\n",
    "    model = get_efficientunet_b5(out_channels=2, concat_input=True, pretrained=False)\n",
    "    \n",
    "    state = torch.load(checkpoint, map_location=torch.device(device))\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    model.eval()\n",
    "    return model.to(device)\n",
    "    \n",
    "seg_model = get_axial_segmentation_model(segmentation_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7c3197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:46.453082Z",
     "iopub.status.busy": "2022-10-17T23:12:46.452739Z",
     "iopub.status.idle": "2022-10-17T23:12:51.764045Z",
     "shell.execute_reply": "2022-10-17T23:12:51.763036Z"
    },
    "papermill": {
     "duration": 5.323167,
     "end_time": "2022-10-17T23:12:51.766525",
     "exception": false,
     "start_time": "2022-10-17T23:12:46.443358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from effdet import create_model\n",
    "\n",
    "def get_axial_detection_model(checkpoint, image_size=512):\n",
    "    model = create_model('efficientdetv2_ds' , bench_task='predict' , num_classes=1 , image_size=(image_size, image_size), pretrained=False, max_det_per_image=1)\n",
    "\n",
    "    state = torch.load(checkpoint, map_location=torch.device(device))\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    \n",
    "    model = model.eval()\n",
    "    return model.to(device)\n",
    "\n",
    "det_model = get_axial_detection_model(axial_det_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7108e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.784444Z",
     "iopub.status.busy": "2022-10-17T23:12:51.784126Z",
     "iopub.status.idle": "2022-10-17T23:12:51.794719Z",
     "shell.execute_reply": "2022-10-17T23:12:51.793844Z"
    },
    "papermill": {
     "duration": 0.021497,
     "end_time": "2022-10-17T23:12:51.796708",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.775211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_axial_boundary_from_segmentation(seg, pixel_spacing, throw=100, tol=0.2, max_mm=100):\n",
    "    \"\"\"\n",
    "    seg : H x W\n",
    "    \"\"\"\n",
    "    image_size = seg.shape[0]\n",
    "    min_size = min(image_size, max_mm / pixel_spacing)\n",
    "    \n",
    "    rows, columns = seg.nonzero(as_tuple=True)\n",
    "    rows.sort()\n",
    "    columns.sort()\n",
    "    \n",
    "    throw = min(len(rows) // 2, throw)\n",
    "    \n",
    "    if(len(rows)) == 0:\n",
    "        return torch.tensor([0, 0, image_size, image_size]).to(device)\n",
    "    \n",
    "    xmin, xmax = columns[throw], columns[-throw]\n",
    "    ymin, ymax = rows[throw], rows[-throw]\n",
    "    \n",
    "    w = (xmax - xmin) * (1 + tol)\n",
    "    h = (ymax - ymax) * (1 + tol)\n",
    "    new_size = max(w, h, min_size)\n",
    "    new_size = min(image_size, new_size)\n",
    "    \n",
    "    xcenter, ycenter = (xmax + xmin) / 2, (ymax + ymin) / 2\n",
    "    \n",
    "    xmin = torch.min(torch.tensor(image_size - new_size), xcenter - new_size / 2)\n",
    "    xmin = xmin.clip(min=0)\n",
    "    \n",
    "    ymin = torch.min(torch.tensor(image_size - new_size), ycenter - new_size / 2)\n",
    "    ymin = ymin.clip(min=0)\n",
    "    \n",
    "    return torch.stack([xmin, ymin, xmin + new_size, ymin + new_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7093b06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.812173Z",
     "iopub.status.busy": "2022-10-17T23:12:51.811907Z",
     "iopub.status.idle": "2022-10-17T23:12:51.817300Z",
     "shell.execute_reply": "2022-10-17T23:12:51.816157Z"
    },
    "papermill": {
     "duration": 0.015599,
     "end_time": "2022-10-17T23:12:51.819607",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.804008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_seg(x, model, img_size=256):\n",
    "    \"\"\"\n",
    "    return: N x 1 x H x W\n",
    "    \"\"\"\n",
    "    x = TF.resize(x, (img_size, img_size))\n",
    "    logits = model(x)\n",
    "\n",
    "    classification_score, mse_score = logits.sigmoid().chunk(2, dim=1)\n",
    "    classification_pred = classification_score.gt(0.5).float()\n",
    "    pred = (classification_pred * mse_score)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d73c7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.835425Z",
     "iopub.status.busy": "2022-10-17T23:12:51.834660Z",
     "iopub.status.idle": "2022-10-17T23:12:51.841049Z",
     "shell.execute_reply": "2022-10-17T23:12:51.840139Z"
    },
    "papermill": {
     "duration": 0.0161,
     "end_time": "2022-10-17T23:12:51.842926",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.826826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_axial_boundary(segs, pixel_spacings, seg_img_size=256):\n",
    "    boundary_list = []\n",
    "    for i in range(segs.shape[0]):\n",
    "        seg = segs[i, 0, :, :]\n",
    "        \n",
    "        boundary = get_axial_boundary_from_segmentation(seg, pixel_spacings[i], throw=int(100 / 512 * seg_img_size), tol=0.2, max_mm=100 / 512 * seg_img_size)\n",
    "        boundary_list.append(boundary)\n",
    "    boundary_list = torch.stack(boundary_list, axis=0) * (512. / seg_img_size)\n",
    "    return boundary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b63c9933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.858404Z",
     "iopub.status.busy": "2022-10-17T23:12:51.858140Z",
     "iopub.status.idle": "2022-10-17T23:12:51.867369Z",
     "shell.execute_reply": "2022-10-17T23:12:51.866385Z"
    },
    "papermill": {
     "duration": 0.019486,
     "end_time": "2022-10-17T23:12:51.869446",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.849960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict_det(x, model):\n",
    "    \n",
    "    bboxes = model(x) # N x 1 x 6\n",
    "    \n",
    "    return bboxes[:, 0, :]\n",
    "    \n",
    "    \n",
    "def crop_resize_images(imgs_tensor, boundary_list, img_size=512):\n",
    "    croped_list = []\n",
    "    for i in range(imgs_tensor.shape[0]):\n",
    "        xmin, ymin, xmax, ymax = boundary_list[i, :]\n",
    "        xmin, ymin, xmax, ymax = int(xmin), int(ymin), int(xmax), int(ymax)\n",
    "        # print(xmin, ymin, xmax, ymax)\n",
    "        croped = TF.crop(imgs_tensor[i, :, :, :], top=ymin, left=xmin, height=ymax-ymin, width=xmax-xmin)\n",
    "        croped = TF.resize(croped, (img_size, img_size))\n",
    "        croped_list.append(croped)\n",
    "        \n",
    "    return torch.stack(croped_list, 0)\n",
    "\n",
    "def get_original_bbox(bbox, boundary):\n",
    "    scale = 512. / (boundary[:, [2]] - boundary[:, [0]])\n",
    "    \n",
    "    org_bbox = bbox / scale\n",
    "    org_bbox[:, 0] += boundary[:, 0]\n",
    "    org_bbox[:, 1] += boundary[:, 1]\n",
    "    org_bbox[:, 2] += boundary[:, 0]\n",
    "    org_bbox[:, 3] += boundary[:, 1]\n",
    "    \n",
    "    return org_bbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1761d857",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.884393Z",
     "iopub.status.busy": "2022-10-17T23:12:51.884140Z",
     "iopub.status.idle": "2022-10-17T23:12:51.889234Z",
     "shell.execute_reply": "2022-10-17T23:12:51.888350Z"
    },
    "papermill": {
     "duration": 0.014858,
     "end_time": "2022-10-17T23:12:51.891200",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.876342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bbox_class(seg, bbox):\n",
    "    \"\"\"\n",
    "    label 은 0.125 의 단위로, \n",
    "    seg: H x W\n",
    "    bbox: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox.int()\n",
    "    area = seg[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    # print(area)\n",
    "    result = torch.mean(area[area>0])\n",
    "    result = torch.round(result / 0.125)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "038f293c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.905986Z",
     "iopub.status.busy": "2022-10-17T23:12:51.905725Z",
     "iopub.status.idle": "2022-10-17T23:12:51.910968Z",
     "shell.execute_reply": "2022-10-17T23:12:51.909989Z"
    },
    "papermill": {
     "duration": 0.015036,
     "end_time": "2022-10-17T23:12:51.913209",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.898173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bbox_class_list(seg_list, seg_bboxes):\n",
    "    class_list = []\n",
    "    for i in range(seg_list.shape[0]):\n",
    "        class_index = get_bbox_class(seg_list[i, :, :], seg_bboxes[i, :])\n",
    "        class_list.append(class_index)\n",
    "        \n",
    "    return torch.stack(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daafc4c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.928529Z",
     "iopub.status.busy": "2022-10-17T23:12:51.928258Z",
     "iopub.status.idle": "2022-10-17T23:12:51.935526Z",
     "shell.execute_reply": "2022-10-17T23:12:51.934720Z"
    },
    "papermill": {
     "duration": 0.017294,
     "end_time": "2022-10-17T23:12:51.937629",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.920335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_class_score(scores, class_list, eps=1e-2):\n",
    "    result = scores.new_zeros((scores.shape[0], 8)) + eps\n",
    "    class_list = torch.nan_to_num(class_list).long()\n",
    "    result[torch.arange(scores.shape[0]), class_list] = scores\n",
    "    \n",
    "    return result\n",
    "\n",
    "def check_detection_result(det_result, img_size=512., threshold=0.2):\n",
    "    # throw big bboxes\n",
    "    areas = (det_result[:, 2] - det_result[:, 0]) * (det_result[:, 3] - det_result[:, 1]) / (img_size * img_size)\n",
    "    # print(areas)\n",
    "    big_indices = torch.argwhere(areas > threshold)\n",
    "    det_result[big_indices, 4] = 0.\n",
    "    return det_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abfc7c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.953787Z",
     "iopub.status.busy": "2022-10-17T23:12:51.952993Z",
     "iopub.status.idle": "2022-10-17T23:12:51.959308Z",
     "shell.execute_reply": "2022-10-17T23:12:51.958450Z"
    },
    "papermill": {
     "duration": 0.016415,
     "end_time": "2022-10-17T23:12:51.961355",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.944940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_loss(prob, label):\n",
    "    \n",
    "    pos_weight = np.array([14, 2, 2, 2, 2, 2, 2, 2])\n",
    "    neg_weight = np.array([7, 1, 1, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    score = pos_weight * label * np.log(prob) + neg_weight * (1 - label) * np.log(1 - prob)\n",
    "    \n",
    "    weight_total = pos_weight * label + neg_weight * (1 - label)\n",
    "    \n",
    "    return -score.sum(axis=1) / weight_total.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "070264d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:12:51.976305Z",
     "iopub.status.busy": "2022-10-17T23:12:51.976010Z",
     "iopub.status.idle": "2022-10-17T23:13:51.285123Z",
     "shell.execute_reply": "2022-10-17T23:13:51.283938Z"
    },
    "papermill": {
     "duration": 59.319485,
     "end_time": "2022-10-17T23:13:51.287944",
     "exception": false,
     "start_time": "2022-10-17T23:12:51.968459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:59<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        \n",
    "#         tqdm_iter = tqdm(dl)\n",
    "        for (x, pixel_spacings) in tqdm(dl):\n",
    "            \n",
    "            # x : N x 3 x 512 x 512\n",
    "            x = x.to(device)\n",
    "            \n",
    "            batch_probs = x.new_zeros((x.shape[0], 8)) + 1e-2\n",
    "            \n",
    "            seg_result = predict_seg(x, seg_model)  # N x 1 x 256 x 256\n",
    "            \n",
    "            active_indices = seg_result.sum(axis=[1, 2, 3]).nonzero().reshape(-1)\n",
    "            if active_indices.numel() == 0:\n",
    "                predictions.append(batch_probs)\n",
    "                continue\n",
    "            \n",
    "#             tqdm_iter.set_description(f'{active_indices.numel()}')\n",
    "            if active_indices.numel() != batch_size:\n",
    "                x = x[active_indices, :, :, :]\n",
    "                seg_result = seg_result[active_indices, :, :, :]\n",
    "                pixel_spacings = pixel_spacings[active_indices]\n",
    "            \n",
    "            \n",
    "            axial_boundary = get_axial_boundary(seg_result, pixel_spacings, seg_img_size=256)  # N x 4\n",
    "            \n",
    "#             print(x.shape)\n",
    "            x = crop_resize_images(x, axial_boundary) # N x 3 x 512 x 512 croped\n",
    "            det_result = predict_det(x, det_model)\n",
    "#             det_result = check_detection_result(det_result, threshold=0.1)\n",
    "            \n",
    "            bboxes, scores = get_original_bbox(det_result[:, :4], axial_boundary), det_result[:, 4]\n",
    "#             print(scores)\n",
    "            class_list = get_bbox_class_list(seg_result[:, 0, :, :], bboxes / 2)\n",
    "#             print(class_list)\n",
    "            probs = get_class_score(scores, class_list)\n",
    "            \n",
    "            batch_probs[active_indices, :] = probs\n",
    "#             print(probs)\n",
    "            predictions.append(batch_probs)\n",
    "        \n",
    "        return torch.concat(predictions).cpu().numpy()\n",
    "predictions = predict()\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06543192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:13:51.313727Z",
     "iopub.status.busy": "2022-10-17T23:13:51.312943Z",
     "iopub.status.idle": "2022-10-17T23:13:51.343521Z",
     "shell.execute_reply": "2022-10-17T23:13:51.342382Z"
    },
    "papermill": {
     "duration": 0.045028,
     "end_time": "2022-10-17T23:13:51.345484",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.300456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.22327</th>\n",
       "      <td>0.574853</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.037450</td>\n",
       "      <td>0.033594</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.189582</td>\n",
       "      <td>0.574853</td>\n",
       "      <td>0.126512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.25399</th>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.252099</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.117002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.5876</th>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.126440</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>0.029631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient_overall        C1        C2        C3  \\\n",
       "StudyInstanceUID                                                           \n",
       "1.2.826.0.1.3680043.22327         0.574853  0.070553  0.037450  0.033594   \n",
       "1.2.826.0.1.3680043.25399         0.508683  0.039090  0.016025  0.508683   \n",
       "1.2.826.0.1.3680043.5876          0.127817  0.127817  0.024592  0.035604   \n",
       "\n",
       "                                 C4        C5        C6        C7  \n",
       "StudyInstanceUID                                                   \n",
       "1.2.826.0.1.3680043.22327  0.070707  0.189582  0.574853  0.126512  \n",
       "1.2.826.0.1.3680043.25399  0.252099  0.012320  0.019680  0.117002  \n",
       "1.2.826.0.1.3680043.5876   0.126440  0.023032  0.020248  0.029631  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_effnet_pred = pd.DataFrame(\n",
    "    data=predictions, columns=['patient_overall'] + [f'C{i}' for i in range(1, 8)]\n",
    ")\n",
    "df_test_pred = pd.concat([df_test_slices, df_effnet_pred], axis=1).sort_values(['StudyInstanceUID', 'Slice'])\n",
    "df_patient_pred = df_test_pred.groupby('StudyInstanceUID').apply(lambda df: df.max())\n",
    "df_patient_pred[\"patient_overall\"] = df_patient_pred[[f'C{i}' for i in range(1, 8)]].max(axis=1)\n",
    "df_patient_pred = df_patient_pred[['patient_overall'] + [f'C{i}' for i in range(1, 8)]]\n",
    "df_patient_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b50881e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:13:51.370055Z",
     "iopub.status.busy": "2022-10-17T23:13:51.369524Z",
     "iopub.status.idle": "2022-10-17T23:13:51.374700Z",
     "shell.execute_reply": "2022-10-17T23:13:51.373869Z"
    },
    "papermill": {
     "duration": 0.019466,
     "end_time": "2022-10-17T23:13:51.376712",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.357246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prob = df_patient_pred.values\n",
    "# label = train_df.loc[df_patient_pred.index].values\n",
    "\n",
    "# losses = cal_loss(prob, label)\n",
    "# print(list(losses))\n",
    "# print(losses)\n",
    "# print(np.mean(losses))\n",
    "# list(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85a08b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:13:51.401483Z",
     "iopub.status.busy": "2022-10-17T23:13:51.400509Z",
     "iopub.status.idle": "2022-10-17T23:13:51.417778Z",
     "shell.execute_reply": "2022-10-17T23:13:51.416766Z"
    },
    "papermill": {
     "duration": 0.031652,
     "end_time": "2022-10-17T23:13:51.419879",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.388227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>prediction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.22327</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C1</td>\n",
       "      <td>1.2.826.0.1.3680043.25399</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_patient_overall</td>\n",
       "      <td>1.2.826.0.1.3680043.5876</td>\n",
       "      <td>patient_overall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     row_id           StudyInstanceUID  \\\n",
       "0              1.2.826.0.1.3680043.22327_C1  1.2.826.0.1.3680043.22327   \n",
       "1              1.2.826.0.1.3680043.25399_C1  1.2.826.0.1.3680043.25399   \n",
       "2  1.2.826.0.1.3680043.5876_patient_overall   1.2.826.0.1.3680043.5876   \n",
       "\n",
       "   prediction_type  \n",
       "0               C1  \n",
       "1               C1  \n",
       "2  patient_overall  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv('../input/rsna-2022-cervical-spine-fracture-detection/test.csv')\n",
    "df_test = pd.read_csv(f'../input/rsna-2022-cervical-spine-fracture-detection/test.csv')\n",
    "\n",
    "if df_test.iloc[0].row_id == '1.2.826.0.1.3680043.10197_C1':\n",
    "    # test_images and test.csv are inconsistent in the dev dataset, fixing labels for the dev run.\n",
    "    df_test = pd.DataFrame({\n",
    "        \"row_id\": ['1.2.826.0.1.3680043.22327_C1', '1.2.826.0.1.3680043.25399_C1', '1.2.826.0.1.3680043.5876_patient_overall'],\n",
    "        \"StudyInstanceUID\": ['1.2.826.0.1.3680043.22327', '1.2.826.0.1.3680043.25399', '1.2.826.0.1.3680043.5876'],\n",
    "        \"prediction_type\": [\"C1\", \"C1\", \"patient_overall\"]}\n",
    "    )\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bd6c41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:13:51.444454Z",
     "iopub.status.busy": "2022-10-17T23:13:51.444175Z",
     "iopub.status.idle": "2022-10-17T23:13:51.466515Z",
     "shell.execute_reply": "2022-10-17T23:13:51.465483Z"
    },
    "papermill": {
     "duration": 0.037254,
     "end_time": "2022-10-17T23:13:51.468836",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.431582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_type</th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>fractured</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.22327</th>\n",
       "      <td>1.2.826.0.1.3680043.22327_C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.574853</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.037450</td>\n",
       "      <td>0.033594</td>\n",
       "      <td>0.070707</td>\n",
       "      <td>0.189582</td>\n",
       "      <td>0.574853</td>\n",
       "      <td>0.126512</td>\n",
       "      <td>0.070553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.25399</th>\n",
       "      <td>1.2.826.0.1.3680043.25399_C1</td>\n",
       "      <td>C1</td>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.039090</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.508683</td>\n",
       "      <td>0.252099</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.117002</td>\n",
       "      <td>0.039090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.5876</th>\n",
       "      <td>1.2.826.0.1.3680043.5876_patient_overall</td>\n",
       "      <td>patient_overall</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.127817</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>0.035604</td>\n",
       "      <td>0.126440</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0.020248</td>\n",
       "      <td>0.029631</td>\n",
       "      <td>0.127817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             row_id  \\\n",
       "StudyInstanceUID                                                      \n",
       "1.2.826.0.1.3680043.22327              1.2.826.0.1.3680043.22327_C1   \n",
       "1.2.826.0.1.3680043.25399              1.2.826.0.1.3680043.25399_C1   \n",
       "1.2.826.0.1.3680043.5876   1.2.826.0.1.3680043.5876_patient_overall   \n",
       "\n",
       "                           prediction_type  patient_overall        C1  \\\n",
       "StudyInstanceUID                                                        \n",
       "1.2.826.0.1.3680043.22327               C1         0.574853  0.070553   \n",
       "1.2.826.0.1.3680043.25399               C1         0.508683  0.039090   \n",
       "1.2.826.0.1.3680043.5876   patient_overall         0.127817  0.127817   \n",
       "\n",
       "                                 C2        C3        C4        C5        C6  \\\n",
       "StudyInstanceUID                                                              \n",
       "1.2.826.0.1.3680043.22327  0.037450  0.033594  0.070707  0.189582  0.574853   \n",
       "1.2.826.0.1.3680043.25399  0.016025  0.508683  0.252099  0.012320  0.019680   \n",
       "1.2.826.0.1.3680043.5876   0.024592  0.035604  0.126440  0.023032  0.020248   \n",
       "\n",
       "                                 C7  fractured  \n",
       "StudyInstanceUID                                \n",
       "1.2.826.0.1.3680043.22327  0.126512   0.070553  \n",
       "1.2.826.0.1.3680043.25399  0.117002   0.039090  \n",
       "1.2.826.0.1.3680043.5876   0.029631   0.127817  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = df_test.copy()\n",
    "df_sub = df_sub.set_index('StudyInstanceUID').join(df_patient_pred)\n",
    "df_sub['fractured'] = df_sub.apply(lambda r: r[r.prediction_type], axis=1)\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "958a304f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T23:13:51.494894Z",
     "iopub.status.busy": "2022-10-17T23:13:51.494140Z",
     "iopub.status.idle": "2022-10-17T23:13:51.502541Z",
     "shell.execute_reply": "2022-10-17T23:13:51.501577Z"
    },
    "papermill": {
     "duration": 0.023324,
     "end_time": "2022-10-17T23:13:51.504653",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.481329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub[['row_id', 'fractured']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13064fce",
   "metadata": {
    "papermill": {
     "duration": 0.011423,
     "end_time": "2022-10-17T23:13:51.528934",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.517511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f462183",
   "metadata": {
    "papermill": {
     "duration": 0.011779,
     "end_time": "2022-10-17T23:13:51.552423",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.540644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4d9aef",
   "metadata": {
    "papermill": {
     "duration": 0.011386,
     "end_time": "2022-10-17T23:13:51.575339",
     "exception": false,
     "start_time": "2022-10-17T23:13:51.563953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 242.404406,
   "end_time": "2022-10-17T23:13:53.977777",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-17T23:09:51.573371",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
