{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108a1f7d-a7d6-47ad-af02-6d54964eb7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# import seaborn as sns\n",
    "# import ast\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "effdet_path = \"../third/effdet\"\n",
    "sys.path.append(effdet_path)\n",
    "timm_path = \"../third/timm-pytorch-image-models\"\n",
    "sys.path.append(timm_path)\n",
    "import timm\n",
    "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "yolo_path = \"../third/yolov7_custom\"\n",
    "sys.path.append(yolo_path)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64afe8b9-a916-4a33-9afb-9be48a15bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1+cu116'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f83aad-22c7-4723-afec-fd5e885122cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_model_ver=\"132508\"\n",
    "IMAGE_SIZE=512\n",
    "\n",
    "DATA_DIR = \"/root/autodl-tmp/cervical_spine/\"\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'train_axial_images_jpeg95_croped_132508')\n",
    "MASK_DIR = os.path.join(DATA_DIR, 'segmentation_axial_results_132508')\n",
    "\n",
    "axial_det_checkpoint = os.path.join(DATA_DIR, 'checkpoint', 'axial_detection_effdet_104709-epoch-54.pth')\n",
    "\n",
    "# weights = \"/root/cervical_spine/third/yolov7_custom/runs/train/yolov7-custom9/weights/last.pt\"\n",
    "# weights = \"/root/autodl-tmp/cervical_spine/checkpoint/yolov7-A100-best.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2649c9ca-2152-40fd-b3ba-7505c1e13621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.6200</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.27262</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.21561</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.12351</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.1363</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient_overall  C1  C2  C3  C4  C5  C6  C7\n",
       "StudyInstanceUID                                                      \n",
       "1.2.826.0.1.3680043.6200                 1   1   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.27262                1   0   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.21561                1   0   1   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.12351                0   0   0   0   0   0   0   0\n",
       "1.2.826.0.1.3680043.1363                 1   0   0   0   0   1   0   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv')).set_index('StudyInstanceUID')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d45182-1c8b-4b1f-9e63-d890993b5a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "708779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>Slice</th>\n",
       "      <th>Start</th>\n",
       "      <th>pixel_spacing</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UID_Slice</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10001.0</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10001.1</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10001.2</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10001.3</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10001.4</th>\n",
       "      <td>1.2.826.0.1.3680043.10001</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      StudyInstanceUID  Slice  Start  \\\n",
       "UID_Slice                                                              \n",
       "1.2.826.0.1.3680043.10001.0  1.2.826.0.1.3680043.10001      0      0   \n",
       "1.2.826.0.1.3680043.10001.1  1.2.826.0.1.3680043.10001      1      0   \n",
       "1.2.826.0.1.3680043.10001.2  1.2.826.0.1.3680043.10001      2      0   \n",
       "1.2.826.0.1.3680043.10001.3  1.2.826.0.1.3680043.10001      3      0   \n",
       "1.2.826.0.1.3680043.10001.4  1.2.826.0.1.3680043.10001      4      0   \n",
       "\n",
       "                             pixel_spacing  xmin  ymin   xmax   ymax  \n",
       "UID_Slice                                                             \n",
       "1.2.826.0.1.3680043.10001.0       0.253906   0.0   0.0  512.0  512.0  \n",
       "1.2.826.0.1.3680043.10001.1       0.253906   0.0   0.0  512.0  512.0  \n",
       "1.2.826.0.1.3680043.10001.2       0.253906   0.0   0.0  512.0  512.0  \n",
       "1.2.826.0.1.3680043.10001.3       0.253906   0.0   0.0  512.0  512.0  \n",
       "1.2.826.0.1.3680043.10001.4       0.253906   0.0   0.0  512.0  512.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_boundary_df = pd.read_csv(os.path.join(DATA_DIR, f'infered_boundary_{mask_model_ver}_2.csv'))\n",
    "total_boundary_df['UID_Slice'] = total_boundary_df['StudyInstanceUID'] + '.' + total_boundary_df['Slice'].astype('string')\n",
    "total_boundary_df = total_boundary_df.set_index('UID_Slice').astype({'Slice': int})\n",
    "print(len(total_boundary_df.StudyInstanceUID.unique()))\n",
    "print(len(total_boundary_df))\n",
    "total_boundary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e56c0390-bc7e-43cc-ba6a-5a07b22fc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from effdet import create_model\n",
    "\n",
    "def get_axial_detection_model(checkpoint, image_size=512):\n",
    "    model = create_model('efficientdetv2_ds' , bench_task='predict' , num_classes=1 , image_size=(image_size, image_size), pretrained=False, max_det_per_image=1)\n",
    "\n",
    "    state = torch.load(checkpoint, map_location=torch.device(device))\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    \n",
    "    model = model.eval()\n",
    "    return model.to(device)\n",
    "\n",
    "model = get_axial_detection_model(axial_det_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944087c9-b100-419b-a279-2dfbf450210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = attempt_load(weights, map_location=device)\n",
    "# model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9185ac27-e69a-429f-aabf-9073381323c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_slices = glob.glob(f'{IMAGES_DIR}/1.2.826.0.1.3680043.219*/*')\n",
    "# test_slices = [re.findall(f'{IMAGES_DIR}/(.*)/(.*).jpeg', s)[0] for s in test_slices]\n",
    "\n",
    "# df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice'])\n",
    "# df_test_slices['UID_Slice'] = df_test_slices['StudyInstanceUID'] + '.' + df_test_slices['Slice'].astype('string')\n",
    "# df_test_slices = df_test_slices.set_index('UID_Slice').astype({'Slice': int})\n",
    "# df_test_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e0a67c-df41-45f6-803e-26717aa6d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = total_boundary_df.loc[df_test_slices.index].reset_index()\n",
    "# print(len(df))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd33150-fe96-4131-8527-c784bf77ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataSet(torch.utils.data.Dataset):    \n",
    "    def __init__(self, df, img_dir, mask_dir, transform):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.len = len(self.df)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        s = self.df.iloc[i]\n",
    "        UID = s.StudyInstanceUID\n",
    "        \n",
    "        img_path = os.path.join(self.img_dir, UID, f'{int(s.Slice)}.jpeg')\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        mask_path = os.path.join(self.mask_dir, UID, f'{int(s.Slice)}.png')\n",
    "        mask = Image.open(mask_path)\n",
    "    \n",
    "        mask = mask.crop((s.xmin/2, s.ymin/2, s.xmax/2, s.ymax/2))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img, mask = self.transform(img, mask)\n",
    "        \n",
    "        return img, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "class ImageTransform(nn.Module):\n",
    "    def __init__(self, image_size=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor(),\n",
    "            # T.Normalize(0, 255.),\n",
    "        ])\n",
    "        \n",
    "        self.mask_transform = T.Compose([\n",
    "            T.Resize((256, 256), interpolation=torchvision.transforms.InterpolationMode.NEAREST),\n",
    "            T.ToTensor(),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.transform(x)\n",
    "        mask = self.mask_transform(mask)\n",
    "        return x, mask\n",
    "    \n",
    "# tf = ImageTransform(image_size=IMAGE_SIZE)\n",
    "# ds = ImageDataSet(df, IMAGES_DIR, MASK_DIR, tf)\n",
    "\n",
    "# img, mask = ds[200]\n",
    "# print(img.shape, img.min(), img.max())\n",
    "# print(mask.shape, mask.min(), mask.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50baf1a8-89ff-4720-be80-45763360b3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, mask = ds[100]\n",
    "# _, axs = plt.subplots(1, 2)\n",
    "# axs[0].imshow(img[0, :, :])\n",
    "# axs[1].imshow(mask[0, :, :])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4566346-94ca-42d7-adfe-d02335a562a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# dl = DataLoader(ds, batch_size=batch_size, shuffle=False, num_workers=min(os.cpu_count(), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5d71a1-62b8-4b97-9ce2-644e2130a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_det(model, x):\n",
    "    \n",
    "    bboxes = model(x) # N x 1 x 6\n",
    "    \n",
    "    return bboxes[:, 0, :4], bboxes[:, 0, 4]\n",
    "    \n",
    "#     pred = model(x)[0]\n",
    "#     max_indices = torch.argmax(pred[:, :, 4], dim=1)\n",
    "#     max_values = pred[torch.arange(x.shape[0]), max_indices, :] # N x 6\n",
    "    \n",
    "#     bboxes, scores = max_values[:, :4], max_values[:, 4]\n",
    "#     bboxes[:, 2] += bboxes[:, 0]\n",
    "#     bboxes[:, 3] += bboxes[:, 1]\n",
    "#     return bboxes, scores\n",
    "                \n",
    "def get_bbox_class_list(seg_list, seg_bboxes):\n",
    "    class_list = []\n",
    "    for i in range(seg_list.shape[0]):\n",
    "        class_index = get_bbox_class(seg_list[i, :, :], seg_bboxes[i, :])\n",
    "        class_list.append(class_index)\n",
    "        \n",
    "    return torch.stack(class_list)     \n",
    "\n",
    "\n",
    "def get_bbox_class(seg, bbox):\n",
    "    \"\"\"\n",
    "    label 은 0.125 의 단위로, \n",
    "    seg: H x W\n",
    "    bbox: [xmin, ymin, xmax, ymax]\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = bbox.int()\n",
    "    area = seg[ymin:ymax, xmin:xmax]\n",
    "    \n",
    "    # print(area)\n",
    "    result = torch.mean(area[area>0])\n",
    "    result = torch.round(result / 0.125)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_class_score(scores, class_list, eps=1e-3):\n",
    "    result = scores.new_zeros((scores.shape[0], 8)) + eps\n",
    "    class_list = torch.nan_to_num(class_list).long()\n",
    "    result[torch.arange(scores.shape[0]), class_list] = scores\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def cal_loss(prob, label):\n",
    "    \n",
    "    pos_weight = np.array([14, 2, 2, 2, 2, 2, 2, 2])\n",
    "    neg_weight = np.array([7, 1, 1, 1, 1, 1, 1, 1])\n",
    "    \n",
    "    score = pos_weight * label * np.log(prob) + neg_weight * (1 - label) * np.log(1 - prob)\n",
    "    \n",
    "    weight_total = pos_weight * label + neg_weight * (1 - label)\n",
    "    \n",
    "    return -score.sum(axis=1) / weight_total.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf2925ec-8765-45f9-ba40-e67ab761864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_df(UIDs):\n",
    "    \"\"\"\n",
    "    UIDs : 1.2.826.0.1.3680043.219*\n",
    "    \"\"\"\n",
    "    test_slices = glob.glob(f'{IMAGES_DIR}/{UIDs}/*')\n",
    "    test_slices = [re.findall(f'{IMAGES_DIR}/(.*)/(.*).jpeg', s)[0] for s in test_slices]\n",
    "\n",
    "    df_test_slices = pd.DataFrame(data=test_slices, columns=['StudyInstanceUID', 'Slice'])\n",
    "    df_test_slices['UID_Slice'] = df_test_slices['StudyInstanceUID'] + '.' + df_test_slices['Slice'].astype('string')\n",
    "    # df_test_slices = df_test_slices.set_index('UID_Slice').astype({'Slice': int})\n",
    "    df = total_boundary_df.loc[df_test_slices.UID_Slice].sort_values(['StudyInstanceUID','Slice']).reset_index()\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_loader(df, batch_size=32, image_size=512):\n",
    "    tf = ImageTransform(image_size=image_size)\n",
    "    ds = ImageDataSet(df, IMAGES_DIR, MASK_DIR, tf)\n",
    "    \n",
    "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=min(16, batch_size))\n",
    "    return dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d47c3c-d926-4df1-b2b9-53c6b3742cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 17,
>>>>>>> a3107eae55efa36313c5868869243cd651ff5a44
   "id": "a0c161c1-1330-4736-8133-59dde7f47787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]/root/cervical_spine/final/../third/effdet/effdet/bench.py:55: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  indices_all = cls_topk_indices_all // num_classes\n",
<<<<<<< HEAD
      "100%|██████████| 9/9 [00:14<00:00,  1.59s/it]\n"
=======
      "  2%|▏         | 385/22150 [02:14<2:06:35,  2.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_596172/1123259024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# print(\"max score slice : \", np.argmax(predictions.max(axis=1), axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_596172/1123259024.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(dl, batch_size)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mactive_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mclass_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bbox_class_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m256.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_596172/857482535.py\u001b[0m in \u001b[0;36mpred_det\u001b[0;34m(model, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpred_det\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# N x 1 x 6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cervical_spine/final/../third/effdet/effdet/bench.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, img_info)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mimg_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_scale'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         return _batch_detection(\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mimg_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_det_per_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_det_per_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoft_nms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoft_nms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> a3107eae55efa36313c5868869243cd651ff5a44
     ]
    }
   ],
   "source": [
    "def predict(dl, batch_size):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for x, mask in tqdm(dl):\n",
    "            x = x.to(device)\n",
    "            mask = mask.to(device)\n",
    "            \n",
    "            batch_probs = x.new_zeros((x.shape[0], 8)) + 1e-4\n",
    "            \n",
    "            active_indices = mask.sum(axis=[1, 2, 3]).nonzero().reshape(-1)\n",
    "            \n",
    "            if active_indices.numel() == 0:\n",
    "                predictions.append(batch_probs)\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            # infer_result = torch.zeros((x.shape[0], 9))    \n",
    "            if active_indices.numel() != batch_size:\n",
    "                x = x[active_indices, :, :, :]\n",
    "                mask = mask[active_indices, :, :, :]\n",
    "            \n",
    "            bboxes, scores = pred_det(model, x)\n",
    "            bboxes, scores = get_original_bbox(det_result[:, :4], axial_boundary)\n",
    "            class_list = get_bbox_class_list(mask[:, 0, :, :], bboxes / (IMAGE_SIZE / 256.) )\n",
    "            # print(bboxes)\n",
    "            # print(class_list)\n",
    "            probs = get_class_score(scores, class_list)\n",
    "            \n",
    "            batch_probs[active_indices, :] = probs\n",
    "#             print(probs)\n",
    "            predictions.append(batch_probs)\n",
    "    \n",
    "        return torch.concat(predictions).cpu().numpy()\n",
    "    \n",
    "UID = '1.2.826.0.1.3680043.10051'\n",
    "batch_size=32\n",
    "df = get_test_df(UID)\n",
    "tf = ImageTransform(image_size=512)\n",
    "ds = ImageDataSet(df, IMAGES_DIR, MASK_DIR, tf)\n",
    "\n",
    "dl = DataLoader(ds, batch_size=batch_size, shuffle=False, pin_memory=False, num_workers=16)\n",
    "predictions = predict(dl, batch_size)\n",
    "\n",
    "# print(\"max score slice : \", np.argmax(predictions.max(axis=1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe93e3c-8a46-42f2-9cc8-b99435845e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_indice = np.argmax(predictions.max(axis=1), axis=0)\n",
    "# print(f'{UID}.{max_indice}')\n",
    "# img, mask = ds[max_indice]\n",
    "# plt.imshow(img[2, :, :], cmap='bone')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cec8ec3-4072-4457-acbc-cdca02581d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_overall</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.2.826.0.1.3680043.10051</th>\n",
       "      <td>0.03519</td>\n",
       "      <td>0.03519</td>\n",
       "      <td>0.028541</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.033049</td>\n",
       "      <td>0.030415</td>\n",
       "      <td>0.018386</td>\n",
       "      <td>0.030861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           patient_overall       C1        C2        C3  \\\n",
       "StudyInstanceUID                                                          \n",
       "1.2.826.0.1.3680043.10051          0.03519  0.03519  0.028541  0.025219   \n",
       "\n",
       "                                 C4        C5        C6        C7  \n",
       "StudyInstanceUID                                                   \n",
       "1.2.826.0.1.3680043.10051  0.033049  0.030415  0.018386  0.030861  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_effnet_pred = pd.DataFrame(\n",
    "    data=predictions, columns=['patient_overall'] + [f'C{i}' for i in range(1, 8)]\n",
    ")\n",
    "df_test_pred = pd.concat([df, df_effnet_pred], axis=1).sort_values(['StudyInstanceUID', 'Slice'])\n",
    "df_patient_pred = df_test_pred.groupby('StudyInstanceUID').apply(lambda df: df.max())\n",
    "\n",
    "# clip_value = 1e-3\n",
    "# df_patient_pred[[f'C{i}' for i in range(1, 8)]] = df_patient_pred[[f'C{i}' for i in range(1, 8)]].clip(lower=clip_value, upper=1-clip_value)\n",
    "\n",
    "\n",
    "df_patient_pred[\"patient_overall\"] = df_patient_pred[[f'C{i}' for i in range(1, 8)]].max(axis=1)\n",
    "df_patient_pred = df_patient_pred[['patient_overall'] + [f'C{i}' for i in range(1, 8)]]\n",
    "df_patient_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80b917ec-f386-485d-a534-b351994ff59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_effnet_pred.to_csv(os.path.join(DATA_DIR, 'df_effnet_pred_10251705.csv'))\n",
    "df_test_pred.to_csv(os.path.join(DATA_DIR, 'df_test_pred_10251705.csv'))\n",
    "df_patient_pred.to_csv(os.path.join(DATA_DIR, 'df_patient_pred_10251705.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "175a2318-8f6c-4eba-a65c-267354a24d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0209365504976293\n"
     ]
    }
   ],
   "source": [
    "prob = df_patient_pred.values\n",
    "label = train_df.loc[df_patient_pred.index].values\n",
    "\n",
    "# print(prob.shape)\n",
    "# print(label.shape)\n",
    "\n",
    "losses = cal_loss(prob, label)\n",
    "print(np.mean(losses))\n",
    "# list(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58027e22-08d7-4877-bccd-5fc36d6a92e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "task_code = datetime.now().strftime(\"%H%M%S\")\n",
    "\n",
    "df_patient_pred['losses'] = losses\n",
    "df_patient_pred.to_csv(os.path.join(DATA_DIR,'predictions', f'df_patient_loss_{task_code}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c404bcd-d416-420f-bdfa-30a83b8bef50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a79a65-3902-4350-87cf-fa0162f0f666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
